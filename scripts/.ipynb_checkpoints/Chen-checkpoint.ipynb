{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'lemmatiseTermes' from 'fonctions_index' (/Users/noah/MesDocuments/TAL/TAL_M2_INALCO/Semestre_2/recherche_information/projet/RI_projet_shiyannnn/scripts/fonctions_index.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-302-c48b4e3eb736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfonctions_index\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlitTexteDuFichier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecritTexteDansUnFichier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatiseTexte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormaliseTokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormaliseTokensRequete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatiseTermes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mPARSEUR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'TALISMANE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'lemmatiseTermes' from 'fonctions_index' (/Users/noah/MesDocuments/TAL/TAL_M2_INALCO/Semestre_2/recherche_information/projet/RI_projet_shiyannnn/scripts/fonctions_index.py)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "#   python3 requete-v1.py\n",
    "#\n",
    "#   Traitement d'une requête :\n",
    "#       0. lecture fichier des index (inversé & documents)\n",
    "#       1. lecture de la requête\n",
    "#       2. extraction de ses tokens \n",
    "#       - lemmatisation\n",
    "#       - normalisation \n",
    "#       3. recherche des documents correspondants dans l'index\n",
    "#           par comptage des matchs\n",
    "#       4. affichage des résultats\n",
    "# \n",
    "#   remarque :  ne donne pas d'info sur les termes trouvés\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle \n",
    "import json\n",
    "from fonctions_index import litTexteDuFichier, ecritTexteDansUnFichier, lemmatiseTexte, normaliseTokens, lemmatiseTermes, normaliseTokensRequete\n",
    "\n",
    "PARSEUR = 'TALISMANE'\n",
    "   \n",
    "fiIndex = \"./_index/indexInverse\"\n",
    "fiDocs = \"./_index/indexDocuments\"\n",
    "doCorpus = \"../corpus/miniCorpus/FR/\"\n",
    "corpus_sansBalise = \"../corpus/sans_balises\"\n",
    "\n",
    "fiTxt = \"./_log/tempo.txt\" \n",
    "\n",
    "fiLog = \"./_log/requete.log\"\n",
    "log = \"\"\n",
    "\n",
    "\n",
    "#fonction pour lire le fichier indexDocument\n",
    "def litIndexDocument(fichier):\n",
    "    indexDocuments = dict()\n",
    "    if os.path.isfile (fichier) :\n",
    "        with open(fichier, 'rb') as FI :\n",
    "            indexDocuments = json.load(FI)\n",
    "    return indexDocuments\n",
    "\n",
    "#fonction pour lire le fichier indexInverse\n",
    "def litIndexInverse(fichier):\n",
    "    indexInverse = dict ()\n",
    "    if os.path.isfile (fichier) :\n",
    "        with open(fichier, 'rb') as FI :\n",
    "            indexInverse = json.load(FI)\n",
    "    return indexInverse\n",
    " \n",
    "#trier les termes saisis pour faire la reqête en trois parties\n",
    "def trierTermesDeRequete(requete):\n",
    "    termes_inclure = []\n",
    "    termes_exclure = []\n",
    "    termes_optionnel = []\n",
    "\n",
    "    termes_avec_ponc = list(requete.split(\" \"))\n",
    "    for terme in termes_avec_ponc:\n",
    "        if terme.startswith(\"+\"): \n",
    "            termes_inclure.append(terme[1:])\n",
    "        elif terme.startswith(\"-\"): \n",
    "            termes_exclure.append(terme[1:])\n",
    "        else: termes_optionnel.append(terme)\n",
    "\n",
    "    termes_totals = termes_inclure+termes_exclure+termes_optionnel\n",
    "    return termes_totals, termes_inclure, termes_exclure, termes_optionnel\n",
    "\n",
    "\n",
    "#recherche tous les termes dans l'index et stocker le résultat, retourne un résultat brut\n",
    "def requeteDesTermes(termes, fichier_indexInverse):\n",
    "    resultat_requete = dict ()\n",
    "    for terme in termes:\n",
    "        if terme in fichier_indexInverse:\n",
    "            for liste in fichier_indexInverse[terme]:\n",
    "                if resultat_requete.__contains__(liste[0]):\n",
    "                    resultat_requete[liste[0]][terme] = liste[1]\n",
    "                else:\n",
    "                    valeur = {terme:liste[1]}\n",
    "                    resultat_requete[liste[0]] = valeur\n",
    "    return resultat_requete\n",
    "\n",
    "\n",
    "#filtrer les résultats en fonctions des symboles \"+\" et \"-\"\n",
    "def filtrerLeResultat(resultat_brut, termes_a_inclure, termes_a_exclure):\n",
    "    def detecterLesTermes(document):\n",
    "        termes = document[1]\n",
    "        if all(terme in termes for terme in termes_a_inclure) == False:\n",
    "            return False\n",
    "        if any(terme in termes for terme in termes_a_exclure):\n",
    "            return False\n",
    "        return True\n",
    "    nbMatch_filtre = dict(filter(detecterLesTermes, resultat_brut.items()))\n",
    "    return nbMatch_filtre\n",
    "\n",
    "\n",
    "def standardiseLesTermes(liste):\n",
    "    liste = lemmatiseTermes(liste)\n",
    "    liste = normaliseTokensRequete(liste)\n",
    "    return liste\n",
    "\n",
    "# 6. calculer les scores avec TF-IDF\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------main-------------------------------------------\n",
    "\n",
    "#lire les fichiers de l'index de documents et l'index inversé\n",
    "indexDocuments = litIndexDocument(fiDocs)\n",
    "indexInverse = litIndexInverse(fiIndex)\n",
    "\n",
    "#input la requête\n",
    "print(\"votre requête ?\")\n",
    "requete = input()\n",
    "print(\"votre requête est: \", requete)\n",
    "log += \"\\nrequête: %s \\n\" % (requete)\n",
    "\n",
    "#stocker les termes triés\n",
    "termes_totals, termes_inclure, termes_exclure, termes_optionnel = trierTermesDeRequete(requete)\n",
    "termes_totals_string = \" \".join(termes_totals)\n",
    "ecritTexteDansUnFichier (termes_totals_string, fiTxt) \n",
    "\n",
    "#lematiser et normaliser tous les termes de requête\n",
    "tokens = lemmatiseTermes(termes_totals)\n",
    "termes_totals_a_chercher = normaliseTokensRequete (tokens)\n",
    "log += \"\\ntermes: %s \\n\" % (termes_totals_a_chercher)\n",
    "\n",
    "#lamatiser et normaliser les termes iclures et les termes exculres\n",
    "termes_inclure_final = standardiseLesTermes(termes_inclure)\n",
    "termes_exclure_final = standardiseLesTermes(termes_exclure)\n",
    "termes_optionnel_final = standardiseLesTermes(termes_optionnel)\n",
    "\n",
    "#faire la reqête, chercher tous les documents qui comprennent tous les termes saisis, on obtient un résultat brut\n",
    "nbMatch = requeteDesTermes(termes_totals_a_chercher, indexInverse)\n",
    "log += \"\\nrésultat: %s \\n\" % (str(nbMatch))\n",
    "\n",
    "#filtrer le résultat brut en fonction des symboles \"+\" et \"-\"\n",
    "nbMatch_final = filtrerLeResultat(nbMatch, termes_inclure_final, termes_exclure_final)\n",
    "log += \"\\nrésultats filtrés: %s\\n\" % str(nbMatch_final)\n",
    "\n",
    "#affichage du résultat dans le terminal\n",
    "print(\"\\n{nombre} documents ont été trouvés!\\n\".format(nombre=len(nbMatch_final)))\n",
    "print(nbMatch_final)\n",
    "\n",
    "\n",
    "#extraire les sous-titres s'ils existent et les stocker dans \"log\"\n",
    "log += \"\\nrésultats détaillées: \\n\"\n",
    "for doc, nb in nbMatch_final.items():#sorted(nbMatch.items(), key=lambda item: item[0], reverse=True) :\n",
    "    info_document = indexDocuments[str(doc)]\n",
    "    nom_fichier = info_document[0]\n",
    "    titre_complet = info_document[1]\n",
    "\n",
    "    if \"\\n\\n\" in titre_complet:\n",
    "        titre_principal = titre_complet[:titre_complet.index(\"\\n\\n\")]\n",
    "        sous_titre = titre_complet[titre_complet.index(\"\\n\\n\")+2:]\n",
    "        log += f\"nom de fichier: {nom_fichier}\\n titre de texte: {titre_principal}\\n sous-titre: {sous_titre}\\n termes trouvés dans ce fichier: {nb}\\n\\n\"\n",
    "    else:\n",
    "        log += f\"nom de fichier: {nom_fichier}\\n titre de texte: {titre_complet}\\n termes trouvés dans ce fichier: {nb}\\n\\n\"\n",
    "\n",
    "\n",
    "\n",
    "# sauvegarde du log\n",
    "ecritTexteDansUnFichier (log, fiLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['je', '-ne', '+sais', '-pas']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'je ne sais pas'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mots_list = \"je -ne +sais -pas\"\n",
    "tokens = mots_list.split(\" \")\n",
    "tokens_sans_ponc=[]\n",
    "\n",
    "print(tokens)\n",
    "for i in tokens:\n",
    "    if i[0] == \"-\" or i[0] == \"+\":\n",
    "        tokens_sans_ponc.append(i[1:])\n",
    "    else:\n",
    "        tokens_sans_ponc.append(i)\n",
    "cave = \" \".join(tokens_sans_ponc)\n",
    "cave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-eb6a6b4609e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: join() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "aa = \"\"\n",
    "aa.join([\"s\",\"o\",\"c\",\"i\",\"a\",'l'],split=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除加减号的版本\n",
    "def lemmatiseTokensRequete(fichier):\n",
    "    tokensLemmePos = []\n",
    "    fiParse = fichier + \".par\"\n",
    "\n",
    "    #supprimer le \"+\" et le \"-\" des termes de la requête\n",
    "    requete_termes = litTexteDuFichier(fichier)\n",
    "    termes_avec_ponc = requete_termes.split(\" \")\n",
    "    liste_termes_sans_ponc = []\n",
    "\n",
    "    for terme in termes_avec_ponc:\n",
    "        if terme[0] == \"-\" or terme[0] == \"+\":\n",
    "            liste_termes_sans_ponc.append(terme[1:])\n",
    "        else:\n",
    "            liste_termes_sans_ponc.append(terme)\n",
    "    termes_a_traiter = \" \".join(liste_termes_sans_ponc)\n",
    "\n",
    "    #écrire à nouveau les termes sans ponctuations dans le fichier \"tempo.txt\"\n",
    "    ecritTexteDansUnFichier(termes_a_traiter, fichier)\n",
    "    \n",
    "    # execute TreeTagger\n",
    "    if detect(requete_termes) == \"fr\":\n",
    "        cmd = \"tree-tagger-french\"\n",
    "    else:\n",
    "        cmd = \"tree-tagger-english\"\n",
    "    os.system(\"%s %s > %s\" % (cmd, fichier, fiParse))\n",
    "\n",
    "    # lit le csv produit par treeTagger\n",
    "    with open(fiParse, \"r\") as FI:\n",
    "        for ligne in FI:\n",
    "            ligne = ligne.strip()\n",
    "            defToken = ligne.split(\"\\t\")\n",
    "            # filtre les tokens vides\n",
    "            if len(defToken) >= 3:\n",
    "                if defToken[2] != \"<unknown>\":\n",
    "                    # ajouter les tokens lemmatisés dans la liste \n",
    "                    tokensLemmePos.append(defToken[2])\n",
    "                else:\n",
    "                    tokensLemmePos.append(defToken[0])\n",
    "    # renvoie une liste de tokens (lemme)\n",
    "    return tokensLemmePos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copie de la fonction de \"fonctions_index.py\"\n",
    "def lemmatiseTokenRequete(fichier):\n",
    "    tokensLemmePos = []\n",
    "    fiParse = fichier + \".par\"\n",
    "\n",
    "\n",
    "    # execute TreeTagger\n",
    "    cmd = \"tree-tagger-french\"\n",
    "    os.system(\"%s %s > %s\" % (cmd, fichier, fiParse))\n",
    "    # lit le csv produit par treeTagger\n",
    "    with open(fiParse, \"r\") as FI:\n",
    "        for ligne in FI:\n",
    "            ligne = ligne.strip()\n",
    "            defToken = ligne.split(\"\\t\")\n",
    "            # filtre les tokens vides\n",
    "            if len(defToken) >= 3:\n",
    "                if defToken[2] != \"<unknown>\":\n",
    "                    # ajouter les tokens lemmatisés dans la liste \n",
    "                    tokensLemmePos.append(defToken[2])\n",
    "                else:\n",
    "                    tokensLemmePos.append(defToken[0])\n",
    "    # renvoie une liste de tokens (lemme)\n",
    "    return tokensLemmePos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = {14: {'chomage': 3, 'citoyen': 1, 'economie': 3, 'societe': 1}, 22: {'chomage': 1, 'citoyen': 1, 'economie': 2, 'societe': 1}, 0: {'citoyen': 1, 'economie': 1}, 5: {'citoyen': 2, 'societe': 1}, 10: {'citoyen': 3, 'societe': 5}, 4: {'economie': 4, 'societe': 3, 'salaire': 3}, 7: {'economie': 1, 'societe': 1}, 11: {'economie': 4, 'societe': 1}, 15: {'economie': 1, 'societe': 4}, 26: {'economie': 9, 'societe': 1}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{14: {'chomage': 3, 'citoyen': 1, 'economie': 3, 'societe': 1},\n",
       " 22: {'chomage': 1, 'citoyen': 1, 'economie': 2, 'societe': 1},\n",
       " 0: {'citoyen': 1, 'economie': 1},\n",
       " 5: {'citoyen': 2, 'societe': 1},\n",
       " 10: {'citoyen': 3, 'societe': 5},\n",
       " 4: {'economie': 4, 'societe': 3, 'salaire': 3},\n",
       " 7: {'economie': 1, 'societe': 1},\n",
       " 11: {'economie': 4, 'societe': 1},\n",
       " 15: {'economie': 1, 'societe': 4},\n",
       " 26: {'economie': 9, 'societe': 1}}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_list = []\n",
    "for i in resultats:\n",
    "    mots_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 22, 0, 5, 10, 4, 7, 11, 15, 26]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mots_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "resultats_finals = copy.deepcopy(resultats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{14: {'chomage': 3, 'citoyen': 1, 'economie': 3, 'societe': 1},\n",
       " 22: {'chomage': 1, 'citoyen': 1, 'economie': 2, 'societe': 1},\n",
       " 0: {'citoyen': 1, 'economie': 1},\n",
       " 5: {'citoyen': 2, 'societe': 1},\n",
       " 10: {'citoyen': 3, 'societe': 5},\n",
       " 4: {'economie': 4, 'societe': 3, 'salaire': 3},\n",
       " 7: {'economie': 1, 'societe': 1},\n",
       " 11: {'economie': 4, 'societe': 1},\n",
       " 15: {'economie': 1, 'societe': 4},\n",
       " 26: {'economie': 9, 'societe': 1}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats_finals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "requete = [\"Chômages\",\"citoyens\",\"+Économie\",\"+sociétés\",\"-salaire\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "requete_finale = [\"chomage\",\"citoyen\",\"+economie\",\"+societe\",\"-salaire\"]#7,11,15,26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-42da3ac67da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultats_finals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mterme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequete_finale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mterme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mterme\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultats_finals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mresultats_finals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 10"
     ]
    }
   ],
   "source": [
    "rrr = {}\n",
    "for document in resultats_finals:\n",
    "    for terme in requete_finale:\n",
    "        if terme.startswith(\"-\") and terme[1:] in resultats_finals[document]:\n",
    "            resultats_finals.pop(document)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = list(resultats_finals.items())\n",
    "mots_a_traiter = ag[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'economie': 4, 'societe': 3, 'salaire': 3}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mots_a_traiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(term in mots_a_traiter for term in requete_finale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (term in mots_a_traiter for term in requete_finale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(term in mots_a_traiter for term in requete_finale)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for terme in requete_finale:\n",
    "    for document in resultats_finals:\n",
    "        if (terme[0] == \"+\") and (terme[1:] in resultats_finals[document]):\n",
    "            if document in rrr:\n",
    "                pass\n",
    "            else:\n",
    "                rrr[document] = resultats_finals.get(document)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs +dsdfd -sfe +dd\n",
      "['dfs', '+dsdfd', '-sfe', '+dd']\n"
     ]
    }
   ],
   "source": [
    "inputt = input()\n",
    "aa = list(inputt.split(\" \"))\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treetaggerwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-241-ae39d607adce>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-241-ae39d607adce>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    texte = extraitTexteDuFichier(fichier, nom_fichier)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "tokensLemmePos = []\n",
    "    texte = extraitTexteDuFichier(fichier, nom_fichier)\n",
    "    if detect(texte) == \"fr\":\n",
    "        tagger = treetaggerwrapper.TreeTagger(TAGLANG=\"fr\")\n",
    "        tags = tagger.tag_text(texte)\n",
    "        lang = \"FR\"\n",
    "    else:\n",
    "        tagger = treetaggerwrapper.TreeTagger(TAGLANG=\"en\")\n",
    "        tags = tagger.tag_text(texte)\n",
    "        lang = \"EN\"\n",
    "    for ligne in tags:\n",
    "        ligne = ligne.strip()\n",
    "        defToken = ligne.split(\"\\t\")\n",
    "        # filtre les tokens vides\n",
    "        if len(defToken) >= 3:\n",
    "            # reduit aux lemmes et pos\n",
    "            token = [defToken[2], defToken[1]]\n",
    "            tokensLemmePos.append(token)\n",
    "    # renvoie une liste de tokens (lemme et pos)\n",
    "    return tokensLemmePos, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_test = [\"chômages\",\"salaires\",\"citoyenne\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG=\"fr\")\n",
    "aa = tagger.tag_text(termes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chômages\\tNOM\\tchômage', 'salaires\\tNOM\\tsalaire', 'citoyenne\\tNOM\\tcitoyen']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in aa:\n",
    "    i = i.strip()\n",
    "    token = i.split(\"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chômages salaires citoyenne'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(termes_test)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG=\"fr\")\n",
    "aa = tagger.tag_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chômages\\tNOM\\tchômage', 'salaires\\tNOM\\tsalaire', 'citoyenne\\tNOM\\tcitoyen']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatiseTermes(liste):\n",
    "    tokensLemme = []\n",
    "    # execute TreeTagger\n",
    "    texte = \" \".join(liste)\n",
    "    if detect(texte) == \"fr\":\n",
    "        tagger = treetaggerwrapper.TreeTagger(TAGLANG=\"fr\")\n",
    "        tags = tagger.tag_text(texte)\n",
    "    else:\n",
    "        tagger = treetaggerwrapper.TreeTagger(TAGLANG=\"en\")\n",
    "        tags = tagger.tag_text(texte)\n",
    "        lang = \"EN\"\n",
    "    for ligne in tags:\n",
    "        ligne = ligne.strip()\n",
    "        defToken = ligne.split(\"\\t\")\n",
    "        # filtre les tokens vides\n",
    "        if len(defToken) >= 3:\n",
    "            # reduit aux lemmes et pos\n",
    "            token = [defToken[2]]\n",
    "            tokensLemme.append(token)\n",
    "    # renvoie une liste de tokens (lemme et pos)\n",
    "    return tokensLemme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['chômage'], ['salaire'], ['citoyen']]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatiseTermes(termes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatiseTokensRequete(fichier):\n",
    "    tokensLemmePos = []\n",
    "    fiParse = fichier + \".par\"\n",
    "    \n",
    "    # execute TreeTagger\n",
    "    termes_requete = litTexteDuFichier(fichier)\n",
    "    if detect(termes_requete) == \"fr\":\n",
    "        cmd = \"tree-tagger-french\"\n",
    "    else:\n",
    "        cmd = \"tree-tagger-english\"\n",
    "    os.system(\"%s %s > %s\" % (cmd, fichier, fiParse))\n",
    "\n",
    "    # lit le csv produit par treeTagger\n",
    "    with open(fiParse, \"r\") as FI:\n",
    "        for ligne in FI:\n",
    "            ligne = ligne.strip()\n",
    "            defToken = ligne.split(\"\\t\")\n",
    "            # filtre les tokens vides\n",
    "            if len(defToken) >= 3:\n",
    "                if defToken[2] != \"<unknown>\":\n",
    "                    # ajouter les tokens lemmatisés dans la liste \n",
    "                    tokensLemmePos.append(defToken[2])\n",
    "                else:\n",
    "                    tokensLemmePos.append(defToken[0])\n",
    "    # renvoie une liste de tokens (lemme)\n",
    "    return tokensLemmePos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-dominated': [[6, 1]],\n",
       " '-qui': [[8, 1]],\n",
       " '000-strong': [[13, 1]],\n",
       " '1.3bn': [[25, 1]],\n",
       " '1.6bn': [[25, 1]],\n",
       " '1.9bn': [[25, 1]],\n",
       " '100bn': [[25, 1]],\n",
       " '10bn': [[19, 1], [25, 1]],\n",
       " '10m': [[28, 1]],\n",
       " '11-hour': [[21, 1]],\n",
       " '18.522bn': [[28, 1]],\n",
       " '1920s': [[24, 1]],\n",
       " '1930s': [[24, 1]],\n",
       " '1940s': [[24, 2]],\n",
       " '1950s': [[24, 1]],\n",
       " '1960s': [[3, 1], [6, 1], [18, 1]],\n",
       " '1970s': [[3, 1], [6, 1], [18, 1], [20, 1], [24, 1]],\n",
       " '1980s': [[6, 6], [18, 1], [29, 1]],\n",
       " '1990s': [[2, 1], [6, 2], [13, 1], [21, 1], [24, 1]],\n",
       " '19th': [[25, 1]],\n",
       " '1bn': [[3, 1]],\n",
       " '1er': [[5, 2], [22, 1]],\n",
       " '2.2m': [[19, 1]],\n",
       " '2.8bn': [[28, 1]],\n",
       " '2.955bn': [[28, 1]],\n",
       " '200m': [[25, 1]],\n",
       " '22bn': [[28, 1]],\n",
       " '24bn': [[19, 1]],\n",
       " '2bn': [[19, 1]],\n",
       " '2m': [[24, 1]],\n",
       " '3.28m': [[19, 1]],\n",
       " '30-foot-high': [[24, 1]],\n",
       " '37e': [[27, 1]],\n",
       " '3m': [[1, 1], [19, 1]],\n",
       " '4.42m': [[19, 1]],\n",
       " '400bn': [[6, 1]],\n",
       " '4bn': [[28, 1]],\n",
       " '4e': [[27, 1]],\n",
       " '4m': [[19, 1]],\n",
       " '4th': [[1, 1]],\n",
       " '4x4': [[8, 1]],\n",
       " '50m': [[1, 1]],\n",
       " '51st': [[25, 1]],\n",
       " '55e': [[11, 1]],\n",
       " '55th': [[25, 1]],\n",
       " '5e': [[27, 1]],\n",
       " '5th': [[1, 1]],\n",
       " '600bn': [[6, 1]],\n",
       " '600m': [[3, 1]],\n",
       " '6e': [[27, 1]],\n",
       " '6th': [[1, 1]],\n",
       " '70bn': [[12, 1]],\n",
       " '7bn-': [[25, 1]],\n",
       " '7e': [[27, 1]],\n",
       " '7th': [[1, 1]],\n",
       " '800m': [[3, 1]],\n",
       " '80bn': [[19, 1]],\n",
       " '81bn': [[6, 1]],\n",
       " '@card@': [[0, 46],\n",
       "  [1, 20],\n",
       "  [2, 27],\n",
       "  [3, 8],\n",
       "  [4, 20],\n",
       "  [5, 26],\n",
       "  [6, 28],\n",
       "  [7, 21],\n",
       "  [8, 6],\n",
       "  [9, 54],\n",
       "  [10, 35],\n",
       "  [11, 43],\n",
       "  [12, 21],\n",
       "  [13, 49],\n",
       "  [14, 60],\n",
       "  [15, 64],\n",
       "  [16, 19],\n",
       "  [17, 37],\n",
       "  [18, 16],\n",
       "  [19, 43],\n",
       "  [20, 31],\n",
       "  [21, 24],\n",
       "  [22, 42],\n",
       "  [23, 15],\n",
       "  [24, 4],\n",
       "  [25, 30],\n",
       "  [26, 41],\n",
       "  [27, 25],\n",
       "  [28, 48],\n",
       "  [29, 43]],\n",
       " '@ord@': [[1, 1],\n",
       "  [2, 3],\n",
       "  [3, 2],\n",
       "  [9, 1],\n",
       "  [16, 1],\n",
       "  [17, 3],\n",
       "  [18, 4],\n",
       "  [19, 4],\n",
       "  [25, 1],\n",
       "  [28, 2],\n",
       "  [29, 2]],\n",
       " 'a-t-il': [[7, 1], [16, 2], [22, 1]],\n",
       " 'ababa': [[1, 1]],\n",
       " 'abandon': [[6, 1], [10, 1], [25, 1], [28, 1]],\n",
       " 'abc': [[7, 1], [12, 1]],\n",
       " 'abces': [[9, 1]],\n",
       " 'abdallah': [[23, 1]],\n",
       " 'abdel': [[1, 1], [3, 1], [23, 2], [27, 1]],\n",
       " 'abdul': [[9, 1], [13, 1]],\n",
       " 'abdullah': [[3, 1], [9, 1], [13, 1]],\n",
       " 'abeba': [[27, 1]],\n",
       " 'abet': [[29, 1]],\n",
       " 'ability': [[2, 1], [6, 1]],\n",
       " 'able': [[6, 1], [13, 1], [20, 1], [21, 1]],\n",
       " 'abm': [[0, 1], [2, 2], [5, 3]],\n",
       " 'aboi': [[23, 1]],\n",
       " 'abolish': [[28, 1]],\n",
       " 'abolition': [[1, 1]],\n",
       " 'abord': [[0, 1], [5, 1], [7, 1], [9, 2], [11, 1], [23, 3], [27, 2]],\n",
       " 'abou': [[22, 1]],\n",
       " 'abrahams': [[1, 1], [27, 1]],\n",
       " 'abri': [[15, 2]],\n",
       " 'absence': [[8, 1], [10, 1], [22, 1]],\n",
       " 'absolute': [[17, 1]],\n",
       " 'absolution': [[7, 1]],\n",
       " 'absorb': [[6, 1], [21, 1]],\n",
       " 'abu': [[17, 1]],\n",
       " 'abuja': [[15, 1]],\n",
       " 'abuse': [[21, 1]],\n",
       " 'abusif': [[5, 1]],\n",
       " 'academic': [[17, 1]],\n",
       " 'accede': [[28, 1]],\n",
       " 'accept': [[3, 2], [6, 1], [12, 1], [13, 1], [17, 2], [18, 1]],\n",
       " 'acceptance': [[6, 1]],\n",
       " 'acces': [[11, 1], [26, 1]],\n",
       " 'access': [[6, 1], [25, 3]],\n",
       " 'accession': [[28, 3]],\n",
       " 'accommodate': [[3, 1], [24, 1]],\n",
       " 'accommodation': [[28, 1]],\n",
       " 'accompany': [[28, 1]],\n",
       " 'accord': [[0, 3],\n",
       "  [1, 1],\n",
       "  [2, 1],\n",
       "  [3, 2],\n",
       "  [5, 10],\n",
       "  [6, 1],\n",
       "  [8, 1],\n",
       "  [13, 1],\n",
       "  [14, 1],\n",
       "  [16, 12],\n",
       "  [17, 5],\n",
       "  [18, 4],\n",
       "  [19, 4],\n",
       "  [21, 2],\n",
       "  [22, 2],\n",
       "  [23, 7],\n",
       "  [24, 1],\n",
       "  [25, 2],\n",
       "  [26, 1],\n",
       "  [28, 2],\n",
       "  [29, 1]],\n",
       " 'accords': [[5, 1]],\n",
       " 'account': [[3, 1], [12, 1], [19, 1], [25, 1]],\n",
       " 'accountability': [[25, 1]],\n",
       " 'accra': [[1, 1], [27, 1]],\n",
       " 'accroissement': [[26, 1]],\n",
       " 'accs': [[27, 1]],\n",
       " 'accumulate': [[28, 1]],\n",
       " 'accumulation': [[26, 1]],\n",
       " 'accusation': [[0, 2], [11, 1], [25, 1], [29, 4]],\n",
       " 'accuse': [[2, 2], [3, 1], [13, 1], [17, 1], [25, 1]],\n",
       " 'acerac': [[15, 1]],\n",
       " 'acerbe': [[22, 1]],\n",
       " 'acerbic': [[17, 1]],\n",
       " 'achat': [[4, 3], [8, 1], [14, 2]],\n",
       " 'achieve': [[1, 1], [3, 7], [29, 2]],\n",
       " 'achievement': [[3, 2]],\n",
       " 'acide': [[8, 1]],\n",
       " 'acknowledge': [[13, 1], [29, 2]],\n",
       " 'acquis': [[14, 3], [23, 3], [28, 3]],\n",
       " 'acquisition': [[0, 1]],\n",
       " 'acss': [[1, 1]],\n",
       " 'act': [[0, 1],\n",
       "  [1, 8],\n",
       "  [2, 2],\n",
       "  [3, 3],\n",
       "  [6, 1],\n",
       "  [9, 1],\n",
       "  [13, 2],\n",
       "  [18, 1],\n",
       "  [28, 1],\n",
       "  [29, 2]],\n",
       " 'acte': [[5, 1], [8, 1], [27, 5]],\n",
       " 'acteur': [[0, 1], [5, 2], [27, 1]],\n",
       " 'actif': [[10, 1], [11, 1], [15, 1]],\n",
       " 'action': [[2, 1],\n",
       "  [3, 1],\n",
       "  [9, 1],\n",
       "  [10, 2],\n",
       "  [17, 1],\n",
       "  [20, 2],\n",
       "  [22, 1],\n",
       "  [23, 4],\n",
       "  [25, 2]],\n",
       " 'actionnaire': [[4, 2], [7, 3]],\n",
       " 'actionnarial': [[26, 1]],\n",
       " 'active': [[25, 1]],\n",
       " 'activist': [[12, 1], [20, 3]],\n",
       " 'activite': [[9, 1], [10, 1], [14, 1], [26, 1]],\n",
       " 'activity': [[13, 2], [17, 1], [20, 2]],\n",
       " 'actor': [[28, 1]],\n",
       " 'actual': [[1, 1], [21, 1], [24, 1]],\n",
       " 'actualite': [[7, 1]],\n",
       " 'actuel': [[0, 1], [10, 2], [11, 4], [22, 2], [23, 2]],\n",
       " 'actuelle': [[5, 1], [10, 1]],\n",
       " 'ad': [[24, 1]],\n",
       " 'adamant': [[29, 1]],\n",
       " 'adapt': [[12, 1]],\n",
       " 'adaptation': [[14, 1]],\n",
       " 'add': [[3, 1], [20, 1]],\n",
       " 'addis': [[1, 1], [27, 1]],\n",
       " 'addition': [[1, 2]],\n",
       " 'additional': [[20, 1]],\n",
       " 'address': [[1, 1], [2, 2], [3, 1], [12, 1], [18, 2], [29, 3]],\n",
       " 'adepte': [[9, 1], [27, 1]],\n",
       " 'adhesion': [[11, 1], [14, 4]],\n",
       " 'adieu': [[4, 1]],\n",
       " 'adjectif': [[8, 1]],\n",
       " 'adjustment': [[28, 1]],\n",
       " 'administratif': [[5, 1], [11, 1]],\n",
       " 'administration': [[0, 2],\n",
       "  [2, 2],\n",
       "  [3, 5],\n",
       "  [5, 2],\n",
       "  [11, 1],\n",
       "  [15, 6],\n",
       "  [19, 4],\n",
       "  [23, 5],\n",
       "  [25, 1],\n",
       "  [29, 2]],\n",
       " 'administrative': [[25, 1]],\n",
       " 'admirable': [[11, 1], [25, 1]],\n",
       " 'adolescent': [[8, 3]],\n",
       " 'adopt': [[1, 1],\n",
       "  [2, 2],\n",
       "  [13, 1],\n",
       "  [19, 1],\n",
       "  [21, 1],\n",
       "  [24, 1],\n",
       "  [25, 1],\n",
       "  [28, 2]],\n",
       " 'adoptif': [[4, 1]],\n",
       " 'adoption': [[1, 1], [4, 1], [7, 1], [14, 3], [21, 1], [27, 2]],\n",
       " 'adorability': [[24, 1]],\n",
       " 'adorateur': [[8, 1]],\n",
       " 'adorn': [[21, 1]],\n",
       " 'adresse': [[16, 1]],\n",
       " 'adult': [[24, 1]],\n",
       " 'advanced': [[15, 1], [19, 1], [29, 1]],\n",
       " 'advancement': [[1, 1]],\n",
       " 'advani': [[9, 1], [13, 1]],\n",
       " 'advantage': [[6, 2], [13, 3], [19, 1], [29, 1]],\n",
       " 'adventure': [[21, 1]],\n",
       " 'adversaire': [[9, 1]],\n",
       " 'adversarial': [[24, 1]],\n",
       " 'adversary': [[13, 1]],\n",
       " 'advertisement': [[20, 2]],\n",
       " 'advertiser': [[12, 2]],\n",
       " 'advertising': [[12, 3], [24, 1]],\n",
       " 'advice': [[17, 1]],\n",
       " 'adviser': [[2, 1], [19, 2], [28, 1], [29, 1]],\n",
       " 'advisor': [[3, 1]],\n",
       " 'advisory': [[1, 1], [27, 1]],\n",
       " 'advocate': [[1, 3], [2, 1], [13, 1], [19, 1], [25, 1]],\n",
       " 'aerien': [[0, 1], [22, 1]],\n",
       " 'aeroport': [[9, 1]],\n",
       " 'affair': [[1, 2], [3, 1], [13, 1], [19, 1]],\n",
       " 'affaire': [[0, 2],\n",
       "  [4, 2],\n",
       "  [7, 2],\n",
       "  [9, 4],\n",
       "  [14, 2],\n",
       "  [16, 2],\n",
       "  [23, 2],\n",
       "  [26, 1],\n",
       "  [27, 1]],\n",
       " 'affaires': [[11, 1]],\n",
       " 'affect': [[3, 2], [6, 1]],\n",
       " 'affectif': [[4, 1]],\n",
       " 'affiche': [[8, 1]],\n",
       " 'affide': [[26, 1]],\n",
       " 'affiliation': [[26, 1]],\n",
       " 'affirm': [[3, 1]],\n",
       " 'affirmative': [[0, 1]],\n",
       " 'affirme-t-il': [[9, 1]],\n",
       " 'affligeant': [[0, 1], [26, 1]],\n",
       " 'afford': [[12, 1], [13, 1], [21, 1], [25, 1], [28, 1], [29, 1]],\n",
       " 'affrontement': [[23, 2]],\n",
       " 'afghan': [[9, 5], [13, 2]],\n",
       " 'afghanistan': [[0, 1], [2, 3], [5, 2], [9, 3], [13, 6], [29, 1]],\n",
       " 'afp': [[7, 1], [12, 1]],\n",
       " 'africa': [[1, 10], [18, 1], [19, 19], [25, 2], [29, 1]],\n",
       " 'africain': [[11, 1], [15, 8], [27, 19]],\n",
       " 'african': [[1, 18], [15, 3], [19, 13], [25, 1], [27, 1]],\n",
       " 'afrikaner': [[27, 1]],\n",
       " 'afrikaners': [[1, 1]],\n",
       " 'afrique': [[0, 1], [15, 16], [16, 1], [27, 11]],\n",
       " 'afro-americains': [[27, 1]],\n",
       " 'afro-american': [[1, 1]],\n",
       " 'aftermath': [[19, 1]],\n",
       " 'again': [[0, 1]],\n",
       " 'age': [[2, 1]],\n",
       " 'agence': [[0, 1], [12, 1]],\n",
       " 'agency': [[24, 1], [29, 1]],\n",
       " 'agenda': [[1, 1], [25, 1]],\n",
       " 'agent': [[6, 2], [26, 2]],\n",
       " 'aggiornamento': [[7, 1]],\n",
       " 'agglomeration': [[8, 1], [23, 1]],\n",
       " 'aggravation': [[16, 1], [23, 2]],\n",
       " 'aggressive': [[20, 1]],\n",
       " 'aggressor': [[29, 1]],\n",
       " 'agree': [[2, 2], [3, 3], [13, 1], [17, 1], [18, 4], [28, 1], [29, 2]],\n",
       " 'agreement': [[2, 10], [3, 6], [5, 1], [17, 1], [18, 6], [29, 2]],\n",
       " 'agressif': [[10, 1]],\n",
       " 'agricole': [[8, 1], [14, 2]],\n",
       " 'agricultural': [[28, 2]],\n",
       " 'agriculture': [[14, 2], [28, 1]],\n",
       " 'aharonot': [[10, 1], [20, 1]],\n",
       " 'aid': [[12, 1], [13, 1], [28, 1]],\n",
       " 'aide': [[0, 2], [7, 1], [9, 1], [11, 1]],\n",
       " 'aids': [[25, 5]],\n",
       " 'aiea': [[0, 1]],\n",
       " 'aigu': [[16, 1]],\n",
       " 'ailleurs': [[11, 1]],\n",
       " 'aim': [[1, 3], [3, 3], [6, 1], [19, 1], [20, 4], [29, 1]],\n",
       " 'ainsi': [[7, 1]],\n",
       " 'air': [[8, 2], [15, 1], [24, 1], [26, 1]],\n",
       " 'air-conditioned': [[24, 3]],\n",
       " 'aire': [[8, 3]],\n",
       " 'airforce': [[19, 1]],\n",
       " 'airline': [[24, 1]],\n",
       " 'airlines': [[4, 2], [21, 2]],\n",
       " 'airport': [[13, 1]],\n",
       " 'airspace': [[17, 1], [29, 1]],\n",
       " 'airwaves': [[12, 1]],\n",
       " 'aise': [[16, 1]],\n",
       " 'ajournement': [[23, 1]],\n",
       " 'ajouta-t-il': [[10, 1]],\n",
       " 'ajustement': [[26, 1]],\n",
       " 'al': [[9, 1], [13, 1]],\n",
       " 'al-assad': [[3, 2]],\n",
       " 'al-baradei': [[29, 1]],\n",
       " 'al-hanoun': [[10, 1], [20, 1]],\n",
       " 'al-muqataa': [[17, 1]],\n",
       " 'al-qaida': [[0, 2], [2, 1], [5, 1], [9, 1], [13, 1], [29, 2]],\n",
       " 'al-sadat': [[18, 1]],\n",
       " 'al-sadate': [[16, 1]],\n",
       " 'al-sharaa': [[3, 1]],\n",
       " 'al-sharif': [[17, 2], [22, 1]],\n",
       " 'alain': [[3, 1], [7, 1], [12, 1], [23, 1]],\n",
       " 'alarm': [[29, 2]],\n",
       " 'alarming': [[12, 1]],\n",
       " 'alcatel': [[7, 2], [12, 2]],\n",
       " 'aleatoire': [[10, 1], [14, 1]],\n",
       " 'aleksander': [[28, 1]],\n",
       " 'alexandre': [[14, 1]],\n",
       " 'algerian': [[1, 1]],\n",
       " 'algerien': [[27, 1]],\n",
       " 'ali': [[9, 1], [13, 1]],\n",
       " 'alien': [[12, 1]],\n",
       " 'alienate': [[13, 1]],\n",
       " 'alienation': [[9, 1], [13, 1]],\n",
       " 'alinea': [[27, 1]],\n",
       " 'alive': [[29, 1]],\n",
       " 'all': [[9, 1], [13, 1], [25, 1]],\n",
       " 'all-out': [[3, 1], [29, 1]],\n",
       " 'all-time': [[17, 1]],\n",
       " 'all-white': [[24, 1]],\n",
       " 'allechant': [[15, 1]],\n",
       " 'allee': [[8, 1]],\n",
       " 'alleged': [[29, 2]],\n",
       " 'allegement': [[0, 1]],\n",
       " 'allegre': [[8, 1]],\n",
       " 'allemagne': [[0, 5]],\n",
       " 'allemand': [[11, 1], [14, 3]],\n",
       " 'allemands': [[14, 1]],\n",
       " 'alley': [[24, 1]],\n",
       " 'alliance': [[0, 1], [7, 2], [10, 1], [12, 1], [20, 1], [28, 1], [29, 1]],\n",
       " 'allie': [[0, 2], [5, 2], [15, 1], [23, 1], [26, 2]],\n",
       " 'allocate': [[25, 1]],\n",
       " 'allow': [[2, 1], [6, 1], [18, 2], [21, 1], [24, 1], [25, 1]],\n",
       " 'allowance': [[3, 1]],\n",
       " 'allumage': [[8, 1]],\n",
       " 'allusion': [[10, 1]],\n",
       " 'ally': [[2, 4], [3, 2], [6, 2], [13, 1], [19, 1], [29, 4]],\n",
       " 'alors': [[14, 1], [23, 1]],\n",
       " 'alt-rock': [[24, 1]],\n",
       " 'alternatif': [[8, 1], [10, 1]],\n",
       " 'alternative': [[6, 1], [17, 1], [20, 1], [24, 2]],\n",
       " 'amazon': [[4, 1], [21, 1], [24, 1]],\n",
       " 'amazonie': [[8, 1]],\n",
       " 'ambassade': [[15, 1], [23, 1]],\n",
       " 'ambassadeur': [[15, 2]],\n",
       " 'ambassador': [[19, 2]],\n",
       " 'ambiance': [[4, 1], [8, 2], [21, 1]],\n",
       " 'ambiguite': [[11, 1]],\n",
       " 'ambition': [[0, 1], [29, 2]],\n",
       " 'ame': [[4, 3], [7, 1], [8, 2]],\n",
       " 'amelioration': [[5, 1]],\n",
       " 'amenable': [[3, 2], [17, 1]],\n",
       " 'amendement': [[5, 2]],\n",
       " 'amendment': [[2, 2]],\n",
       " 'amenity': [[21, 1]],\n",
       " 'amerada': [[15, 1], [19, 1]],\n",
       " 'america': [[1, 1], [4, 1], [6, 2], [21, 1], [29, 1]],\n",
       " 'americain': [[0, 8],\n",
       "  [5, 15],\n",
       "  [7, 1],\n",
       "  [8, 2],\n",
       "  [10, 1],\n",
       "  [11, 2],\n",
       "  [15, 12],\n",
       "  [16, 1],\n",
       "  [22, 1],\n",
       "  [23, 13],\n",
       "  [26, 17],\n",
       "  [27, 2]],\n",
       " 'americaine': [[5, 1]],\n",
       " 'americains': [[0, 1], [4, 1], [5, 1], [8, 1], [11, 1], [14, 1], [26, 1]],\n",
       " 'american': [[2, 2], [6, 3], [20, 1], [24, 2], [25, 1], [29, 1]],\n",
       " 'americano-sovietique': [[27, 1]],\n",
       " 'americans': [[2, 1], [6, 1], [21, 1], [24, 2], [28, 1]],\n",
       " 'amerique': [[0, 1], [8, 1], [15, 4], [26, 2]],\n",
       " 'ami': [[0, 2], [4, 1], [7, 1], [9, 1], [10, 1], [20, 1]],\n",
       " 'amman': [[3, 1], [23, 1]],\n",
       " 'amnon': [[10, 1], [20, 1]],\n",
       " 'amount': [[1, 1], [21, 1], [25, 1]],\n",
       " 'amour': [[4, 1]],\n",
       " 'amp': [[9, 1], [21, 1]],\n",
       " 'ampleur': [[26, 1], [27, 1]],\n",
       " 'ampoule': [[4, 1]],\n",
       " 'amram': [[17, 1], [22, 2]],\n",
       " 'an': [[0, 2],\n",
       "  [5, 2],\n",
       "  [7, 2],\n",
       "  [8, 1],\n",
       "  [9, 6],\n",
       "  [10, 1],\n",
       "  [11, 4],\n",
       "  [14, 1],\n",
       "  [15, 2],\n",
       "  [16, 3],\n",
       "  [22, 4],\n",
       "  [23, 1],\n",
       "  [26, 1],\n",
       "  [27, 1]],\n",
       " 'analogue': [[5, 1], [11, 1], [26, 1]],\n",
       " 'ancetre': [[8, 1], [27, 1]],\n",
       " 'anchor': [[24, 2]],\n",
       " 'ancien': [[0, 1],\n",
       "  [5, 2],\n",
       "  [7, 1],\n",
       "  [8, 1],\n",
       "  [9, 3],\n",
       "  [10, 5],\n",
       "  [11, 1],\n",
       "  [14, 3],\n",
       "  [16, 1],\n",
       "  [22, 1],\n",
       "  [23, 1],\n",
       "  [26, 3],\n",
       "  [27, 1]],\n",
       " 'angeles': [[24, 1]],\n",
       " 'anger': [[17, 1]],\n",
       " 'anglais': [[5, 1], [26, 1], [27, 2]],\n",
       " 'angoissantes': [[0, 1]],\n",
       " 'angoisse': [[10, 1], [23, 1]],\n",
       " 'angola': [[15, 4], [19, 3]],\n",
       " 'angry': [[13, 1]],\n",
       " 'anguish': [[3, 1], [20, 1]],\n",
       " 'anima': [[4, 1]],\n",
       " 'animateur': [[4, 1]],\n",
       " 'ankle': [[21, 1]],\n",
       " 'annan': [[11, 2], [25, 2]],\n",
       " 'annee': [[0, 2],\n",
       "  [4, 2],\n",
       "  [5, 1],\n",
       "  [7, 1],\n",
       "  [8, 9],\n",
       "  [9, 9],\n",
       "  [10, 3],\n",
       "  [11, 1],\n",
       "  [14, 2],\n",
       "  [15, 1],\n",
       "  [16, 7],\n",
       "  [22, 4],\n",
       "  [23, 3],\n",
       "  [26, 9]],\n",
       " 'annexe': [[5, 1]],\n",
       " 'annihilate': [[20, 1]],\n",
       " 'annonce-t-il': [[0, 1]],\n",
       " 'annonceur': [[7, 2]],\n",
       " 'announce': [[12, 1], [21, 2]],\n",
       " 'annual': [[17, 1], [25, 2]],\n",
       " 'annuel': [[11, 1], [15, 1]],\n",
       " 'annulation': [[15, 1]],\n",
       " 'anonyme': [[8, 1]],\n",
       " 'anouar': [[16, 1]],\n",
       " 'ansar': [[13, 1]],\n",
       " 'answer': [[1, 1], [18, 1]],\n",
       " 'antagonise': [[19, 1]],\n",
       " 'antan': [[0, 1]],\n",
       " 'anterieur': [[11, 1], [23, 2]],\n",
       " 'anthrax': [[2, 1]],\n",
       " 'anthropologist': [[24, 1]],\n",
       " 'anthropologue': [[8, 1]],\n",
       " 'anti-anthrax': [[25, 1]],\n",
       " 'anti-ballistic': [[2, 1], [29, 1]],\n",
       " 'anti-banlieue': [[8, 1]],\n",
       " 'anti-communist': [[6, 2]],\n",
       " 'anti-indian': [[13, 1]],\n",
       " 'anti-indien': [[9, 1]],\n",
       " 'anti-personnel': [[2, 2], [29, 1]],\n",
       " 'anti-racist': [[28, 1]],\n",
       " 'anti-semitic': [[3, 1]],\n",
       " 'anti-sprawl': [[24, 1]],\n",
       " 'anti-suburban': [[24, 1]],\n",
       " 'anti-tank': [[2, 1]],\n",
       " 'anti-war': [[29, 1]],\n",
       " 'antibalistique': [[5, 1]],\n",
       " 'antibiotic': [[25, 1]],\n",
       " 'antibiotique': [[11, 1]],\n",
       " 'antichar': [[5, 1]],\n",
       " 'anticommunisme': [[26, 1]],\n",
       " 'anticommuniste': [[26, 1]],\n",
       " 'antidote': [[8, 1], [24, 1]],\n",
       " 'antilles': [[27, 1]],\n",
       " 'antimissile': [[5, 5]],\n",
       " 'antinomique': [[15, 1]],\n",
       " 'antipalestinienne': [[22, 1]],\n",
       " 'antipersonnel': [[0, 1], [5, 2]],\n",
       " 'antique': [[24, 1]],\n",
       " 'antisemite': [[23, 1]],\n",
       " 'anwar': [[18, 1]],\n",
       " 'anxious': [[29, 1]],\n",
       " 'anything': [[17, 1], [21, 1]],\n",
       " 'aol': [[24, 2]],\n",
       " 'aol-time': [[8, 1]],\n",
       " 'aopig': [[15, 3], [19, 3]],\n",
       " 'aout': [[9, 1], [10, 1]],\n",
       " 'apartment': [[24, 1]],\n",
       " 'aphc': [[9, 2], [13, 2]],\n",
       " 'apology': [[3, 1]],\n",
       " 'apotheosis': [[12, 1]],\n",
       " 'appall': [[20, 1]],\n",
       " 'appalling': [[3, 1]],\n",
       " 'appareil': [[10, 2], [11, 1], [23, 1]],\n",
       " 'apparent': [[3, 1], [7, 1]],\n",
       " 'appartenance': [[23, 2]],\n",
       " 'appauvris': [[14, 1]],\n",
       " 'appeal': [[13, 1]],\n",
       " 'appear': [[20, 1], [24, 2], [28, 1]],\n",
       " 'appearance': [[12, 1]],\n",
       " 'appease': [[17, 1]],\n",
       " 'appel': [[8, 1], [9, 1], [11, 1], [15, 1], [23, 2], [26, 1]],\n",
       " 'appelant': [[22, 1]],\n",
       " 'appellation': [[4, 1]],\n",
       " 'appetite': [[29, 1]],\n",
       " 'apple': [[4, 2], [21, 2]],\n",
       " 'application': [[5, 1]],\n",
       " 'apply': [[6, 1]],\n",
       " 'appoint': [[6, 1]],\n",
       " 'appointment': [[25, 1]],\n",
       " 'apport': [[11, 1]],\n",
       " 'approach': [[1, 2], [3, 2], [13, 1], [18, 1]],\n",
       " 'approche': [[4, 1], [16, 3]],\n",
       " 'approval': [[12, 1], [29, 2]],\n",
       " 'approve': [[17, 1], [24, 1], [25, 1]],\n",
       " 'approvisionnement': [[10, 1], [15, 1]],\n",
       " 'appui': [[27, 1]],\n",
       " 'apre': [[26, 1]],\n",
       " 'apres-': [[26, 1]],\n",
       " 'apres-11': [[15, 1]],\n",
       " 'april': [[2, 1], [6, 1]],\n",
       " 'arab': [[3, 6], [17, 2], [18, 1], [20, 4], [29, 2]],\n",
       " 'arab-jewish': [[20, 2]],\n",
       " 'arabe': [[0, 2], [10, 5], [16, 2], [22, 3], [23, 7]],\n",
       " 'arabes': [[10, 1]],\n",
       " 'arabia': [[3, 1], [29, 5]],\n",
       " 'arabic': [[20, 1]],\n",
       " 'arabie': [[0, 3], [23, 1]],\n",
       " 'arabique': [[23, 1]],\n",
       " 'arabo-juif': [[10, 1]],\n",
       " 'arabo-persique': [[0, 1]],\n",
       " 'arabs': [[17, 1], [20, 1]],\n",
       " 'arafat': [[3, 6], [16, 13], [17, 23], [18, 23], [22, 15], [23, 5]],\n",
       " 'arap': [[7, 1], [12, 1]],\n",
       " 'arbitrage': [[0, 1]],\n",
       " 'arbre': [[8, 1]],\n",
       " 'arbuste': [[4, 1]],\n",
       " 'archaisme': [[4, 1]],\n",
       " 'archeological': [[17, 1]],\n",
       " 'archipel': [[26, 2]],\n",
       " 'architect': [[24, 1]],\n",
       " 'architecte': [[8, 1]],\n",
       " 'architectural': [[8, 1], [24, 2]],\n",
       " 'architecture': [[5, 2]],\n",
       " 'area': [[1, 1], [3, 2], [17, 3], [19, 2], [21, 1], [24, 3], [28, 3]],\n",
       " 'arena': [[12, 1]],\n",
       " 'argent': [[4, 1], [7, 1], [11, 1]],\n",
       " 'argue': [[29, 1]],\n",
       " 'argument': [[0, 4], [2, 1], [5, 1], [8, 1], [18, 1], [24, 1], [29, 1]],\n",
       " 'ariel': [[3, 1],\n",
       "  [10, 4],\n",
       "  [16, 2],\n",
       "  [17, 2],\n",
       "  [18, 1],\n",
       "  [20, 2],\n",
       "  [22, 3],\n",
       "  [23, 3]],\n",
       " 'arise': [[1, 1]],\n",
       " 'arlie': [[4, 1], [21, 1]],\n",
       " 'arm': [[2, 2], [13, 1], [18, 1], [29, 1]],\n",
       " 'arme': [[0, 5],\n",
       "  [5, 13],\n",
       "  [9, 6],\n",
       "  [10, 2],\n",
       "  [14, 1],\n",
       "  [15, 1],\n",
       "  [16, 2],\n",
       "  [22, 1],\n",
       "  [23, 1]],\n",
       " 'armed': [[3, 2], [13, 8], [20, 2], [29, 1]],\n",
       " 'armee': [[0, 1], [4, 1], [9, 5], [10, 9], [15, 1], [23, 2], [27, 2]],\n",
       " 'armement': [[5, 1]],\n",
       " 'armes': [[0, 3], [5, 6]],\n",
       " 'armoured': [[13, 1]],\n",
       " 'arms': [[2, 3], [5, 2]],\n",
       " 'armure': [[9, 1]],\n",
       " 'army': [[1, 2], [3, 1], [13, 4], [20, 9], [29, 1]],\n",
       " 'arnold': [[0, 1], [29, 1]],\n",
       " 'arnott': [[4, 1], [21, 1]],\n",
       " 'aron': [[6, 1], [26, 1]],\n",
       " 'arouse': [[28, 1]],\n",
       " 'arrangeant': [[7, 1]],\n",
       " 'arrangement': [[2, 1],\n",
       "  [3, 1],\n",
       "  [5, 1],\n",
       "  [6, 1],\n",
       "  [8, 1],\n",
       "  [16, 3],\n",
       "  [18, 2],\n",
       "  [26, 1],\n",
       "  [29, 1]],\n",
       " 'arrears': [[1, 1]],\n",
       " 'arrest': [[3, 2], [13, 3]],\n",
       " 'arrestation': [[9, 1], [23, 2]],\n",
       " 'arret': [[22, 1]],\n",
       " 'arrete': [[9, 1]],\n",
       " 'arriere': [[9, 1], [23, 1], [27, 1]],\n",
       " 'arrive': [[12, 1], [13, 1], [29, 1]],\n",
       " 'arrive|arrivee': [[9, 1], [14, 1], [22, 1]],\n",
       " 'arsenal': [[2, 1], [5, 1], [7, 1]],\n",
       " 'art': [[0, 1], [4, 1], [8, 1], [21, 1], [24, 1]],\n",
       " 'arterial': [[24, 1]],\n",
       " 'article': [[1, 1],\n",
       "  [2, 1],\n",
       "  [3, 1],\n",
       "  [5, 1],\n",
       "  [7, 1],\n",
       "  [12, 1],\n",
       "  [24, 1],\n",
       "  [27, 1]],\n",
       " 'artillerie': [[10, 2]],\n",
       " 'artillery': [[20, 2]],\n",
       " 'artisanal': [[8, 1]],\n",
       " 'artist': [[12, 1], [28, 1]],\n",
       " 'artiste': [[7, 1]],\n",
       " 'artistes-peintres': [[14, 1]],\n",
       " 'artwork': [[29, 1]],\n",
       " 'asia': [[6, 2]],\n",
       " 'asian': [[6, 2]],\n",
       " 'asiatique': [[26, 2]],\n",
       " 'asie': [[26, 5]],\n",
       " 'ask': [[12, 1], [17, 1], [18, 2], [20, 1], [24, 1], [28, 2]],\n",
       " 'aspect': [[6, 1], [20, 1], [26, 1]],\n",
       " 'aspiration': [[9, 2], [13, 2], [17, 1]],\n",
       " 'aspirin': [[21, 1]],\n",
       " 'aspirine': [[4, 1]],\n",
       " 'aspiring': [[28, 1]],\n",
       " 'assad': [[3, 3], [23, 3]],\n",
       " 'assassinat': [[10, 1], [22, 1]],\n",
       " 'assassinate': [[17, 1]],\n",
       " 'assassination': [[20, 1]],\n",
       " 'assault': [[17, 1], [24, 1], [29, 2]],\n",
       " 'assemblee': [[5, 1], [9, 1], [11, 3], [22, 1]],\n",
       " 'assembly': [[1, 3], [2, 1], [13, 1], [17, 1], [24, 1], [25, 3]],\n",
       " 'asservissement': [[7, 1]],\n",
       " 'assign': [[17, 1]],\n",
       " 'assignment': [[20, 2]],\n",
       " 'assistance': [[1, 1], [25, 1]],\n",
       " 'assistant': [[2, 1]],\n",
       " 'associate': [[21, 1]],\n",
       " 'association': [[1, 1],\n",
       "  [6, 1],\n",
       "  [10, 5],\n",
       "  [14, 1],\n",
       "  [15, 1],\n",
       "  [19, 1],\n",
       "  [20, 1],\n",
       "  [27, 1],\n",
       "  [28, 1]],\n",
       " 'associations': [[10, 1]],\n",
       " 'associe': [[4, 2]],\n",
       " 'assume': [[3, 1], [18, 1], [21, 1]],\n",
       " 'assurance-maladie': [[11, 1]],\n",
       " 'assure': [[2, 2], [3, 1], [21, 2], [29, 1]],\n",
       " 'astound': [[6, 1]],\n",
       " 'astronomique': [[26, 1]],\n",
       " 'astuce': [[8, 1]],\n",
       " 'asymetrique': [[0, 1]],\n",
       " 'asymmetric': [[29, 1]],\n",
       " 'atal': [[9, 1], [13, 1]],\n",
       " 'atelier': [[8, 1]],\n",
       " 'atlantic': [[19, 1]],\n",
       " 'atlantique': [[14, 1], [15, 2]],\n",
       " 'atm': [[4, 2], [21, 4]],\n",
       " 'atmosphere': [[4, 1], [8, 1], [9, 1], [21, 1], [24, 1]],\n",
       " 'atomic': [[29, 1]],\n",
       " 'atomique': [[0, 1]],\n",
       " 'attach': [[19, 2]],\n",
       " 'attachement': [[9, 1]],\n",
       " 'attack': [[1, 1],\n",
       "  [2, 1],\n",
       "  [3, 1],\n",
       "  [13, 3],\n",
       "  [17, 4],\n",
       "  [19, 1],\n",
       "  [20, 1],\n",
       "  [25, 1],\n",
       "  [29, 4]],\n",
       " 'attaque': [[0, 2], [9, 1], [14, 1], [22, 1]],\n",
       " 'atteinte': [[9, 1]],\n",
       " 'attempt': [[3, 2], [13, 1], [29, 2]],\n",
       " 'attend': [[19, 3], [21, 1]],\n",
       " 'attentat': [[0, 3], [5, 1], [9, 1], [11, 1]],\n",
       " 'attentat-suicide': [[9, 1]],\n",
       " 'attentats-suicides': [[0, 1], [22, 1]],\n",
       " 'attente': [[23, 1]],\n",
       " 'attention': [[9, 1], [15, 1], [23, 1], [25, 1], [29, 1]],\n",
       " 'attirail': [[8, 1]],\n",
       " 'attirant': [[4, 1]],\n",
       " 'attitude': [[0, 1], [3, 2], [5, 2], [11, 2], [24, 1]],\n",
       " 'attract': [[28, 2]],\n",
       " 'attractive': [[21, 1], [25, 1]],\n",
       " 'attractiveness': [[6, 1]],\n",
       " 'attribution': [[7, 1]],\n",
       " 'attrition': [[20, 2]],\n",
       " 'au': [[0, 1], [8, 1], [10, 1], [14, 1], [24, 1]],\n",
       " 'auction': [[12, 1]],\n",
       " 'aucun': [[5, 1]],\n",
       " 'aucune': [[5, 1]],\n",
       " 'audacieuse': [[14, 1]],\n",
       " 'audacieux': [[0, 1], [8, 2]],\n",
       " 'audience': [[25, 1]],\n",
       " 'auditeur': [[7, 1]],\n",
       " 'augmentation': [[4, 1], [9, 2]],\n",
       " 'august': [[13, 1]],\n",
       " 'auspice': [[1, 1], [9, 1], [13, 2]],\n",
       " 'australia': [[29, 1]],\n",
       " 'australie': [[0, 1]],\n",
       " 'austrian': [[12, 1]],\n",
       " 'autant': [[10, 1], [11, 1]],\n",
       " 'autel': [[4, 1]],\n",
       " 'auteur': [[0, 1], [7, 1], [26, 1]],\n",
       " 'authentic': [[24, 1]],\n",
       " 'authenticite': [[8, 4]],\n",
       " 'authenticity': [[24, 3]],\n",
       " 'authentique': [[8, 1]],\n",
       " 'authorisation': [[18, 1], [29, 1]],\n",
       " 'authorise': [[25, 1]],\n",
       " 'authority': [[1, 1],\n",
       "  [3, 2],\n",
       "  [13, 1],\n",
       "  [17, 1],\n",
       "  [18, 2],\n",
       "  [19, 1],\n",
       "  [20, 1],\n",
       "  [29, 1]],\n",
       " 'autobiography': [[29, 1]],\n",
       " 'autocentre': [[26, 1]],\n",
       " 'autodetermination': [[27, 1]],\n",
       " 'automated': [[4, 1], [21, 1]],\n",
       " 'automobile': [[8, 1]],\n",
       " 'automobile-based': [[24, 1]],\n",
       " 'autonome': [[22, 1], [23, 1], [26, 1]],\n",
       " 'autonomie': [[9, 1], [23, 1], [26, 1]],\n",
       " 'autonomisation': [[26, 1]],\n",
       " 'autonomous': [[3, 1], [17, 1]],\n",
       " 'autonomy': [[3, 1], [6, 1], [13, 1]],\n",
       " 'autorisation': [[0, 1], [16, 1]],\n",
       " 'autorite': [[0, 2], [4, 1], [10, 1], [16, 5], [22, 2], [23, 5]],\n",
       " 'autre': [[0, 4],\n",
       "  [4, 3],\n",
       "  [5, 3],\n",
       "  [7, 2],\n",
       "  [8, 6],\n",
       "  [9, 8],\n",
       "  [10, 2],\n",
       "  [11, 3],\n",
       "  [14, 3],\n",
       "  [15, 6],\n",
       "  [16, 5],\n",
       "  [22, 4],\n",
       "  [23, 5],\n",
       "  [26, 3],\n",
       "  [27, 1]],\n",
       " 'autres': [[0, 3], [10, 4], [11, 2]],\n",
       " 'autrichien': [[7, 1]],\n",
       " 'aux': [[10, 1]],\n",
       " 'avail': [[1, 1]],\n",
       " 'available': [[1, 1], [3, 1], [19, 1], [24, 1]],\n",
       " 'avait-elle': [[11, 1]],\n",
       " 'avait-il': [[10, 1]],\n",
       " 'avance': [[22, 1]],\n",
       " 'avancee': [[8, 1], [11, 1]],\n",
       " 'avantage': [[4, 2], [9, 1], [15, 1], [26, 1]],\n",
       " 'avantageux': [[26, 1]],\n",
       " 'avare': [[11, 1]],\n",
       " 'avec': [[5, 1]],\n",
       " 'avenement': [[7, 1]],\n",
       " 'avenir': [[4, 2], [16, 1]],\n",
       " 'aventure': [[4, 2], [8, 1]],\n",
       " 'aventurisme': [[10, 1]],\n",
       " 'aventuriste': [[10, 1]],\n",
       " 'average': [[21, 2]],\n",
       " 'avertissement': [[23, 1]],\n",
       " 'aveugle': [[4, 1]],\n",
       " 'avide': [[8, 1]],\n",
       " 'avidite': [[11, 1]],\n",
       " 'aviv': [[20, 2]],\n",
       " 'avnery': [[17, 1], [22, 1]],\n",
       " 'avocat': [[9, 1]],\n",
       " 'avoid': [[1, 1], [3, 4], [6, 1], [17, 1], [19, 2], [28, 1]],\n",
       " 'avoir': [[5, 1]],\n",
       " 'avril': [[5, 1], [10, 1], [26, 1]],\n",
       " 'award': [[12, 1], [19, 1]],\n",
       " 'aware': [[17, 1], [28, 1]],\n",
       " 'awareness': [[20, 1]],\n",
       " 'axe': [[5, 2]],\n",
       " 'axis': [[2, 2]],\n",
       " 'ayalon': [[10, 1], [20, 2]],\n",
       " 'ayant': [[11, 1]],\n",
       " 'azikiwe': [[1, 1], [27, 1]],\n",
       " 'aziz': [[23, 1]],\n",
       " 'b': [[17, 1]],\n",
       " \"b'tselem\": [[20, 1]],\n",
       " 'baby-foot': [[4, 1]],\n",
       " 'bachar': [[23, 2]],\n",
       " 'bacille': [[5, 1]],\n",
       " 'back': [[2, 1], [13, 2], [17, 2], [18, 1], [20, 1], [29, 2]],\n",
       " 'back-to-africa': [[1, 1]],\n",
       " 'backing': [[1, 1]],\n",
       " 'backlash': [[28, 1]],\n",
       " 'bad': [[2, 1], [3, 1], [13, 2], [18, 2], [24, 1]],\n",
       " 'badar': [[9, 1], [13, 1]],\n",
       " 'badge': [[4, 1]],\n",
       " 'bagdad': [[0, 4], [23, 3]],\n",
       " 'baghdad': [[29, 3]],\n",
       " 'bagne': [[0, 1]],\n",
       " 'bail': [[6, 1]],\n",
       " 'bailleur': [[11, 1]],\n",
       " 'bain': [[9, 1]],\n",
       " 'baisse': [[4, 3], [14, 1]],\n",
       " 'baizo': [[6, 1], [26, 1]],\n",
       " 'balai': [[7, 2]],\n",
       " 'balance': [[2, 1], [6, 1], [13, 1], [14, 2], [21, 2], [28, 2], [29, 1]],\n",
       " 'balanced': [[2, 1]],\n",
       " 'balistique': [[0, 2], [5, 2]],\n",
       " 'balkanisation': [[27, 1]],\n",
       " 'ball': [[3, 1]],\n",
       " 'ballade': [[8, 1]],\n",
       " 'balle': [[22, 2]],\n",
       " 'ballistic': [[29, 1]],\n",
       " 'ballon': [[4, 1]],\n",
       " 'balneaire': [[8, 1]],\n",
       " 'ban': [[2, 4], [5, 1], [29, 1]],\n",
       " 'banana': [[19, 1]],\n",
       " 'bananiere': [[15, 1]],\n",
       " 'bancaire': [[14, 1], [26, 1]],\n",
       " 'band': [[13, 1]],\n",
       " 'bande': [[10, 1], [16, 4], [22, 1]],\n",
       " 'bandwagon': [[17, 1]],\n",
       " 'bangladesh': [[9, 1], [13, 1]],\n",
       " 'bank': [[1, 2],\n",
       "  [3, 2],\n",
       "  [4, 1],\n",
       "  [6, 4],\n",
       "  [17, 3],\n",
       "  [18, 7],\n",
       "  [20, 3],\n",
       "  [21, 4],\n",
       "  [25, 2],\n",
       "  [29, 1]],\n",
       " 'banker': [[25, 2]],\n",
       " 'banking': [[6, 1], [28, 1]],\n",
       " 'banlieue': [[8, 9]],\n",
       " 'banlieusard': [[8, 3]],\n",
       " 'banner': [[13, 1]],\n",
       " 'banniere': [[9, 1]],\n",
       " 'banque': [[0, 1], [4, 3], [11, 2], [26, 4], [27, 2]],\n",
       " 'banquier': [[11, 2]],\n",
       " 'baptist': [[4, 1], [21, 1]],\n",
       " 'bar': [[8, 1], [24, 1]],\n",
       " 'barak': [[16, 4], [17, 11], [18, 7], [22, 6]],\n",
       " 'baramula': [[13, 1]],\n",
       " 'baramulla': [[9, 1]],\n",
       " 'barbara': [[4, 1]],\n",
       " 'barbarie': [[0, 1]],\n",
       " 'barbarism': [[29, 1]],\n",
       " 'barbed': [[13, 1]],\n",
       " 'barbele': [[9, 1]],\n",
       " 'bargain': [[6, 1]],\n",
       " 'bargaining': [[17, 3]],\n",
       " 'bargouthi': [[3, 1], [23, 1]],\n",
       " 'baril': [[15, 9]],\n",
       " 'baronial': [[24, 1]],\n",
       " 'barrage': [[10, 1]],\n",
       " 'barrel': [[19, 9]],\n",
       " 'barrier': [[12, 1]],\n",
       " 'barrister': [[13, 1]],\n",
       " 'barry': [[15, 1], [19, 1]],\n",
       " 'bas': [[11, 1], [15, 1], [22, 1]],\n",
       " 'base': [[0, 1],\n",
       "  [1, 1],\n",
       "  [3, 2],\n",
       "  [6, 1],\n",
       "  [8, 1],\n",
       "  [9, 1],\n",
       "  [10, 2],\n",
       "  [13, 1],\n",
       "  [18, 2],\n",
       "  [23, 1],\n",
       "  [26, 1],\n",
       "  [28, 1]],\n",
       " 'bashar': [[3, 1]],\n",
       " 'basic': [[13, 1], [21, 1], [24, 1]],\n",
       " 'basie': [[8, 1], [24, 1]],\n",
       " 'basis': [[2, 1], [19, 1], [20, 2]],\n",
       " 'basket-ball': [[4, 1]],\n",
       " 'basketball': [[21, 1]],\n",
       " 'bastion': [[6, 1], [26, 1]],\n",
       " 'bataille': [[0, 1], [15, 1]],\n",
       " 'bataillon': [[10, 1]],\n",
       " 'bateau': [[9, 1]],\n",
       " 'bateaux-hotels': [[9, 1]],\n",
       " 'batiment': [[11, 1]],\n",
       " 'battalion': [[20, 1]],\n",
       " 'battle': [[19, 1], [29, 1]],\n",
       " 'bayer': [[11, 1], [25, 2]],\n",
       " 'be': [[1, 38],\n",
       "  [2, 59],\n",
       "  [3, 68],\n",
       "  [6, 41],\n",
       "  [12, 68],\n",
       "  [13, 75],\n",
       "  [17, 63],\n",
       "  [18, 46],\n",
       "  [19, 33],\n",
       "  [20, 52],\n",
       "  [21, 51],\n",
       "  [24, 79],\n",
       "  [25, 39],\n",
       "  [28, 84],\n",
       "  [29, 69]],\n",
       " 'bear': [[1, 1], [20, 1], [24, 3], [29, 1]],\n",
       " 'beat': [[20, 1]],\n",
       " 'beau': [[0, 1], [4, 1], [10, 1], [23, 1]],\n",
       " 'beau-frere': [[15, 1]],\n",
       " 'beautiful': [[3, 1]],\n",
       " 'beck': [[4, 1]],\n",
       " 'become': [[2, 1],\n",
       "  [6, 2],\n",
       "  [12, 6],\n",
       "  [13, 2],\n",
       "  [17, 2],\n",
       "  [18, 2],\n",
       "  [19, 4],\n",
       "  [20, 1],\n",
       "  [21, 2],\n",
       "  [24, 1],\n",
       "  [25, 1],\n",
       "  [28, 2],\n",
       "  [29, 4]],\n",
       " 'beer': [[24, 1]],\n",
       " 'beg': [[1, 1], [12, 1]],\n",
       " 'begin': [[2, 1],\n",
       "  [3, 1],\n",
       "  [6, 1],\n",
       "  [12, 1],\n",
       "  [13, 3],\n",
       "  [16, 1],\n",
       "  [17, 2],\n",
       "  [18, 1],\n",
       "  [20, 1],\n",
       "  [24, 1],\n",
       "  [28, 1]],\n",
       " 'beginning': [[1, 2], [17, 1], [19, 1], [24, 2]],\n",
       " 'behaviour': [[3, 1]],\n",
       " 'beijing': [[28, 1]],\n",
       " 'beilin': [[17, 3], [22, 2]],\n",
       " 'being': [[1, 1]],\n",
       " 'beirut': [[13, 1]],\n",
       " 'belantes': [[8, 1]],\n",
       " 'belarus': [[28, 1]],\n",
       " 'belarusians': [[28, 1]],\n",
       " 'belgique': [[0, 1]],\n",
       " 'belgium': [[29, 2]],\n",
       " 'belie': [[20, 1]],\n",
       " 'belief': [[6, 1], [21, 1], [25, 1]],\n",
       " 'believe': [[6, 1],\n",
       "  [13, 3],\n",
       "  [17, 1],\n",
       "  [18, 3],\n",
       "  [20, 1],\n",
       "  [24, 1],\n",
       "  [25, 1],\n",
       "  [28, 2],\n",
       "  [29, 5]],\n",
       " 'bell': [[29, 1]],\n",
       " 'belligerent': [[29, 1]],\n",
       " 'belong': [[19, 1]],\n",
       " 'ben': [[9, 1], [17, 3], [22, 2], [23, 1]],\n",
       " 'beneficiaire': [[7, 1]],\n",
       " 'beneficial': [[6, 1], [12, 1]],\n",
       " 'beneficiary': [[12, 1]],\n",
       " 'beneficier': [[4, 1]],\n",
       " 'benefique': [[26, 1]],\n",
       " 'benefit': [[6, 2], [13, 1], [21, 2], [28, 2]],\n",
       " 'benevole': [[10, 1]],\n",
       " 'benjamin': [[4, 1], [21, 1]],\n",
       " 'bent': [[12, 1]],\n",
       " 'benyamin': [[22, 2]],\n",
       " 'beres': [[14, 1], [28, 1]],\n",
       " 'berlin': [[1, 1], [14, 1], [27, 1], [28, 1]],\n",
       " 'berlin-moscou': [[0, 1]],\n",
       " 'berlusconi': [[7, 3], [12, 2]],\n",
       " 'bernard-henri': [[7, 1], [12, 1]],\n",
       " 'berslusconi': [[12, 1]],\n",
       " 'besieged': [[13, 1]],\n",
       " 'besoin': [[4, 2], [7, 1], [11, 2], [16, 1], [26, 3]],\n",
       " 'bet': [[10, 1], [17, 1], [20, 1], [28, 1], [29, 1]],\n",
       " 'bethleem': [[16, 1]],\n",
       " 'bethlehem': [[18, 1]],\n",
       " 'beton': [[8, 1]],\n",
       " 'betselem': [[10, 1]],\n",
       " 'beyrouth': [[9, 1]],\n",
       " 'bhat': [[9, 1], [13, 1]],\n",
       " 'bhutto': [[9, 1], [13, 1]],\n",
       " 'bialystok': [[14, 1], [28, 1]],\n",
       " 'bidder': [[12, 1]],\n",
       " 'bielorusses': [[14, 1]],\n",
       " 'bielorussie': [[14, 1]],\n",
       " 'bien': [[0, 2], [8, 1], [14, 1]],\n",
       " 'bien-etre': [[4, 1]],\n",
       " 'bienfait': [[26, 1]],\n",
       " 'bienvenu|bienvenue': [[8, 1]],\n",
       " 'biere': [[8, 1]],\n",
       " 'big': [[6, 1], [18, 1], [20, 1], [21, 1], [24, 5], [29, 1]],\n",
       " 'bihari': [[9, 1], [13, 1]],\n",
       " 'bilan': [[5, 2], [14, 2], [27, 1]],\n",
       " 'bilateral': [[6, 1], [26, 2]],\n",
       " 'bill': [[4, 1], [13, 1], [21, 1], [24, 1], [28, 1], [29, 1]],\n",
       " 'billet': [[4, 2]],\n",
       " 'billion': [[13, 1]],\n",
       " 'bin': [[13, 1], [29, 2]],\n",
       " 'bind': [[2, 2], [6, 1], [12, 1], [20, 1], [28, 1]],\n",
       " 'binding': [[2, 2]],\n",
       " 'binge': [[21, 1]],\n",
       " 'binyamin': [[17, 2]],\n",
       " 'biological': [[2, 5], [29, 4]],\n",
       " 'biologique': [[0, 3], [5, 6]],\n",
       " 'bipolar': [[29, 1]],\n",
       " 'bipolarite': [[5, 1]],\n",
       " 'bis': [[27, 1]],\n",
       " 'bismarck': [[11, 1], [25, 1]],\n",
       " 'bit': [[4, 1], [24, 1]],\n",
       " 'bitter': [[6, 1]],\n",
       " 'bizarre': [[21, 1]],\n",
       " 'black': [[1, 3], [20, 4], [27, 1]],\n",
       " 'blackmail': [[25, 1]],\n",
       " 'blame': [[13, 1]],\n",
       " 'blameless': [[13, 1]],\n",
       " 'blanc': [[8, 2], [15, 2]],\n",
       " 'blanche': [[5, 3], [15, 2]],\n",
       " 'blanchis-': [[4, 1]],\n",
       " 'bland': [[24, 3]],\n",
       " 'bleak': [[13, 1], [20, 1]],\n",
       " 'blesse': [[9, 2], [22, 1], [23, 1]],\n",
       " 'blinde': [[9, 1]],\n",
       " 'blithe': [[24, 1]],\n",
       " 'blix': [[0, 2], [29, 2]],\n",
       " 'bloc': [[5, 1], [9, 1], [14, 1], [28, 1]],\n",
       " 'block': [[1, 1], [3, 1], [24, 1]],\n",
       " 'blockade': [[3, 1], [20, 1]],\n",
       " 'blocus': [[23, 1]],\n",
       " 'bloodshed': [[13, 1], [17, 1]],\n",
       " 'bloody': [[17, 1], [20, 1]],\n",
       " 'bloque': [[22, 1]],\n",
       " 'blossom': [[24, 1]],\n",
       " 'blow': [[13, 1]],\n",
       " 'blur': [[12, 1], [21, 1]],\n",
       " 'bmatt': [[1, 1], [27, 1]],\n",
       " 'board': [[25, 1], [28, 1], [29, 1]],\n",
       " 'boast': [[28, 1]],\n",
       " 'boat': [[13, 1]],\n",
       " 'body': [[18, 1], [29, 1]],\n",
       " 'boheme': [[8, 1]],\n",
       " 'bohemian': [[24, 1]],\n",
       " 'boigny': [[27, 1]],\n",
       " 'bois': [[9, 1], [27, 1]],\n",
       " 'boisson': [[4, 1], [8, 1]],\n",
       " 'boite': [[8, 1], [9, 1]],\n",
       " 'bold': [[24, 1], [28, 1], [29, 1]],\n",
       " 'bolster': [[21, 2]],\n",
       " 'bomb': [[20, 2]],\n",
       " 'bombardement': [[14, 1]],\n",
       " 'bombing': [[17, 1], [28, 1]],\n",
       " 'bon': [[0, 1],\n",
       "  [4, 2],\n",
       "  [5, 1],\n",
       "  [8, 4],\n",
       "  [9, 1],\n",
       "  [14, 5],\n",
       "  [15, 3],\n",
       "  [23, 1],\n",
       "  [24, 1],\n",
       "  [26, 1]],\n",
       " 'bone': [[24, 1]],\n",
       " 'book': [[12, 4], [13, 1], [18, 1]],\n",
       " 'bookstore': [[21, 1]],\n",
       " 'boom': [[4, 1], [21, 1]],\n",
       " 'boost': [[21, 1]],\n",
       " 'bord': [[9, 1]],\n",
       " 'border': [[1, 1],\n",
       "  [3, 1],\n",
       "  [9, 1],\n",
       "  [12, 1],\n",
       "  [13, 1],\n",
       "  [17, 4],\n",
       "  [20, 1],\n",
       "  [28, 6]],\n",
       " 'bordure': [[0, 1]],\n",
       " 'borne': [[0, 1]],\n",
       " 'borrow': [[28, 1]],\n",
       " 'bosnia': [[2, 1]],\n",
       " 'boss': [[19, 1]],\n",
       " 'bother': [[13, 1], [17, 1]],\n",
       " 'bottle': [[28, 1]],\n",
       " 'bottom': [[21, 1]],\n",
       " 'bouc': [[26, 1]],\n",
       " 'bouclier': [[9, 1]],\n",
       " 'bounce': [[12, 1]],\n",
       " 'bound': [[20, 1]],\n",
       " 'boundary': [[1, 1]],\n",
       " 'bouquet': [[7, 1]],\n",
       " 'bourrier': [[2, 1]],\n",
       " 'boursier': [[4, 1]],\n",
       " 'bout': [[8, 1], [22, 1]],\n",
       " 'bouteille': [[14, 1]],\n",
       " 'boutique': [[8, 11], [14, 2], [24, 2]],\n",
       " 'bouygues': [[7, 2], [12, 2]],\n",
       " 'bowling': [[8, 1], [24, 1]],\n",
       " 'box': [[1, 1], [2, 1], [13, 2], [24, 2]],\n",
       " 'box-like': [[24, 1]],\n",
       " 'boy': [[20, 1]],\n",
       " 'boycott': [[13, 1]],\n",
       " 'brace': [[28, 1]],\n",
       " 'brand': [[12, 1], [24, 3]],\n",
       " 'bras': [[5, 1]],\n",
       " 'brave': [[1, 1], [17, 1], [22, 1]],\n",
       " 'brazil': [[29, 1]],\n",
       " 'brazilian': [[2, 1], [12, 1]],\n",
       " 'breach': [[20, 1]],\n",
       " 'bread': [[24, 1]],\n",
       " 'breadstuff': [[24, 1]],\n",
       " 'break': [[2, 2], [12, 1], [18, 1], [20, 1], [21, 1], [24, 1], [28, 2]],\n",
       " 'break-up': [[13, 1]],\n",
       " 'breakdown': [[6, 1]],\n",
       " 'breakfast': [[19, 1]],\n",
       " 'breche': [[10, 1]],\n",
       " 'breed': [[13, 2]],\n",
       " 'breizh': [[7, 1], [12, 1]],\n",
       " 'bresil': [[0, 1]],\n",
       " 'bresilien': [[5, 1], [7, 1]],\n",
       " 'breton': [[7, 1], [12, 1]],\n",
       " 'brevet': [[11, 5]],\n",
       " 'bridge': [[13, 1], [17, 1], [28, 1]],\n",
       " 'brigade': [[10, 1]],\n",
       " 'bright': [[24, 1]],\n",
       " 'bring': [[2, 1],\n",
       "  [3, 1],\n",
       "  [6, 1],\n",
       "  [17, 3],\n",
       "  [18, 1],\n",
       "  [20, 3],\n",
       "  [25, 2],\n",
       "  [28, 2],\n",
       "  [29, 1]],\n",
       " 'britanniques': [[0, 1]],\n",
       " 'british': [[1, 3], [27, 1], [29, 1]],\n",
       " 'broadcast': [[12, 4]],\n",
       " 'brochure': [[4, 2], [21, 2]],\n",
       " 'brokerage': [[24, 1]],\n",
       " 'broom': [[12, 1]],\n",
       " 'bros': [[8, 1], [24, 1]],\n",
       " 'brother': [[13, 1]],\n",
       " 'brother-in-law': [[19, 1]],\n",
       " 'brouillard': [[22, 1]],\n",
       " 'brown': [[24, 1]],\n",
       " 'bruising': [[18, 1]],\n",
       " 'brundtland': [[11, 13], [25, 15]],\n",
       " 'brusque': [[23, 1]],\n",
       " 'brussels': [[28, 1]],\n",
       " 'brut': [[11, 1], [15, 5], [26, 1]],\n",
       " 'brutal': [[9, 2], [13, 1], [23, 1], [24, 1]],\n",
       " 'brutalite': [[0, 1]],\n",
       " 'brutality': [[29, 1]],\n",
       " 'bruxelles': [[14, 1]],\n",
       " 'bruyant': [[7, 1]],\n",
       " 'bryant': [[8, 1], [24, 1]],\n",
       " 'bubble': [[6, 1], [21, 1]],\n",
       " 'budget': [[14, 1], [25, 1], [28, 1]],\n",
       " 'budgetaire': [[15, 1]],\n",
       " 'budgetary': [[19, 1]],\n",
       " 'budweiser': [[8, 1], [24, 2]],\n",
       " 'bugs': [[24, 1]],\n",
       " 'build': [[2, 1],\n",
       "  [3, 1],\n",
       "  [6, 1],\n",
       "  [18, 2],\n",
       "  [20, 1],\n",
       "  [21, 1],\n",
       "  [24, 2],\n",
       "  [28, 1]],\n",
       " 'build-a-bear': [[8, 1], [24, 1]],\n",
       " 'building': [[13, 1], [24, 1]],\n",
       " 'bulk': [[24, 1]],\n",
       " 'bulldozer': [[10, 1], [20, 1]],\n",
       " 'bulle': [[26, 1]],\n",
       " 'bullet': [[17, 1]],\n",
       " 'bullet-proof': [[13, 1]],\n",
       " 'bully': [[20, 1]],\n",
       " 'bunker': [[9, 2], [13, 2]],\n",
       " 'bunny': [[24, 1]],\n",
       " 'buoyant': [[6, 1]],\n",
       " 'burbs': [[24, 1]],\n",
       " 'bureau': [[4, 3], [8, 1], [14, 1], [15, 1]],\n",
       " 'bureaucracy': [[6, 1]],\n",
       " 'bureaucrat': [[21, 1], [25, 1]],\n",
       " 'bureaucratic': [[6, 1]],\n",
       " 'bureaucratie': [[26, 1]],\n",
       " 'burghardt': [[1, 1]],\n",
       " 'burghart': [[27, 1]],\n",
       " 'burn': [[20, 1]],\n",
       " 'burner': [[29, 1]],\n",
       " 'burst': [[21, 1]],\n",
       " 'burundi': [[1, 1], [27, 1]],\n",
       " 'bury': [[2, 1]],\n",
       " 'bush': [[0, 7],\n",
       "  [2, 7],\n",
       "  [3, 4],\n",
       "  [5, 8],\n",
       "  [15, 10],\n",
       "  [17, 1],\n",
       "  [19, 8],\n",
       "  [21, 1],\n",
       "  [22, 1],\n",
       "  [23, 2],\n",
       "  [29, 10]],\n",
       " 'business': [[12, 1], [21, 1], [25, 2], [28, 2]],\n",
       " 'businessman': [[28, 2]],\n",
       " 'bustani': [[2, 1], [5, 1]],\n",
       " 'busy': [[24, 1]],\n",
       " 'but': [[0, 3], [10, 2], [22, 1], [23, 2], [27, 2]],\n",
       " 'buy': [[6, 1], [12, 3], [21, 2], [28, 3]],\n",
       " 'by-product': [[21, 1]],\n",
       " 'byway': [[24, 1]],\n",
       " \"c'\": [[22, 1], [27, 2]],\n",
       " 'cabinet': [[11, 1]],\n",
       " 'cachemire': [[9, 21]],\n",
       " 'cachemiri': [[9, 3]],\n",
       " 'cachemiris': [[9, 9]],\n",
       " 'cadre': [[0, 1], [3, 1], [4, 4], [14, 1], [15, 2], [23, 1], [27, 2]],\n",
       " 'cafe': [[4, 1], [7, 2], [8, 1], [12, 2], [21, 1], [24, 1]],\n",
       " 'cage': [[4, 1], [21, 1]],\n",
       " 'calcul': [[26, 1]],\n",
       " 'calculate': [[6, 1], [25, 1]],\n",
       " 'calibre': [[0, 1], [5, 1]],\n",
       " 'california': [[19, 1], [21, 1], [24, 1]],\n",
       " 'californie': [[4, 1], [15, 1]],\n",
       " 'californien': [[8, 1]],\n",
       " 'call': [[1, 1],\n",
       "  [3, 3],\n",
       "  [12, 1],\n",
       "  [13, 2],\n",
       "  [17, 5],\n",
       "  [18, 1],\n",
       "  [20, 6],\n",
       "  [21, 2],\n",
       "  [24, 3],\n",
       "  [25, 3]],\n",
       " 'calm': [[19, 1]],\n",
       " 'calme': [[10, 1], [15, 1]],\n",
       " 'camarade': [[10, 1]],\n",
       " 'camera': [[4, 2], [21, 2]],\n",
       " 'camion': [[10, 1]],\n",
       " 'camp': [[1, 1],\n",
       "  [6, 1],\n",
       "  [9, 1],\n",
       "  [10, 1],\n",
       "  [13, 1],\n",
       "  [14, 1],\n",
       "  [16, 5],\n",
       "  [17, 14],\n",
       "  [18, 3],\n",
       "  [20, 1],\n",
       "  [22, 13],\n",
       "  [26, 1],\n",
       "  [27, 2],\n",
       "  [28, 1]],\n",
       " 'campagne': [[4, 1], [5, 1], [10, 1], [14, 2], [22, 5], [23, 1]],\n",
       " 'campaign': [[2, 1], [3, 1], [17, 3], [19, 1], [20, 1], [28, 3]],\n",
       " 'campaigning': [[17, 1]],\n",
       " 'campus': [[4, 3], [21, 2]],\n",
       " 'canal': [[12, 1]],\n",
       " 'canalsatellite': [[7, 1]],\n",
       " 'cancellation': [[19, 1]],\n",
       " 'candidat': [[5, 1], [7, 1], [14, 1], [15, 1], [22, 2]],\n",
       " 'candidate': [[2, 1], [17, 1]],\n",
       " 'canton': [[23, 1]],\n",
       " 'capable': [[3, 1]],\n",
       " 'capacite': [[26, 2], [27, 2]],\n",
       " 'capacity': [[1, 1], [6, 1]],\n",
       " 'capital': [[0, 1],\n",
       "  [6, 1],\n",
       "  [9, 1],\n",
       "  [13, 1],\n",
       "  [14, 3],\n",
       "  [18, 1],\n",
       "  [26, 1],\n",
       "  [28, 3]],\n",
       " ...}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexInverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "tousLesTermes = []\n",
    "for terme in indexInverse:\n",
    "    tousLesTermes.append(terme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-dominated',\n",
       " '-qui',\n",
       " '000-strong',\n",
       " '1.3bn',\n",
       " '1.6bn',\n",
       " '1.9bn',\n",
       " '100bn',\n",
       " '10bn',\n",
       " '10m',\n",
       " '11-hour',\n",
       " '18.522bn',\n",
       " '1920s',\n",
       " '1930s',\n",
       " '1940s',\n",
       " '1950s',\n",
       " '1960s',\n",
       " '1970s',\n",
       " '1980s',\n",
       " '1990s',\n",
       " '19th',\n",
       " '1bn',\n",
       " '1er',\n",
       " '2.2m',\n",
       " '2.8bn',\n",
       " '2.955bn',\n",
       " '200m',\n",
       " '22bn',\n",
       " '24bn',\n",
       " '2bn',\n",
       " '2m',\n",
       " '3.28m',\n",
       " '30-foot-high',\n",
       " '37e',\n",
       " '3m',\n",
       " '4.42m',\n",
       " '400bn',\n",
       " '4bn',\n",
       " '4e',\n",
       " '4m',\n",
       " '4th',\n",
       " '4x4',\n",
       " '50m',\n",
       " '51st',\n",
       " '55e',\n",
       " '55th',\n",
       " '5e',\n",
       " '5th',\n",
       " '600bn',\n",
       " '600m',\n",
       " '6e',\n",
       " '6th',\n",
       " '70bn',\n",
       " '7bn-',\n",
       " '7e',\n",
       " '7th',\n",
       " '800m',\n",
       " '80bn',\n",
       " '81bn',\n",
       " '@card@',\n",
       " '@ord@',\n",
       " 'a-t-il',\n",
       " 'ababa',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'abces',\n",
       " 'abdallah',\n",
       " 'abdel',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abeba',\n",
       " 'abet',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abm',\n",
       " 'aboi',\n",
       " 'abolish',\n",
       " 'abolition',\n",
       " 'abord',\n",
       " 'abou',\n",
       " 'abrahams',\n",
       " 'abri',\n",
       " 'absence',\n",
       " 'absolute',\n",
       " 'absolution',\n",
       " 'absorb',\n",
       " 'abu',\n",
       " 'abuja',\n",
       " 'abuse',\n",
       " 'abusif',\n",
       " 'academic',\n",
       " 'accede',\n",
       " 'accept',\n",
       " 'acceptance',\n",
       " 'acces',\n",
       " 'access',\n",
       " 'accession',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accompany',\n",
       " 'accord',\n",
       " 'accords',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accra',\n",
       " 'accroissement',\n",
       " 'accs',\n",
       " 'accumulate',\n",
       " 'accumulation',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'acerac',\n",
       " 'acerbe',\n",
       " 'acerbic',\n",
       " 'achat',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acide',\n",
       " 'acknowledge',\n",
       " 'acquis',\n",
       " 'acquisition',\n",
       " 'acss',\n",
       " 'act',\n",
       " 'acte',\n",
       " 'acteur',\n",
       " 'actif',\n",
       " 'action',\n",
       " 'actionnaire',\n",
       " 'actionnarial',\n",
       " 'active',\n",
       " 'activist',\n",
       " 'activite',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actualite',\n",
       " 'actuel',\n",
       " 'actuelle',\n",
       " 'ad',\n",
       " 'adamant',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'add',\n",
       " 'addis',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adepte',\n",
       " 'adhesion',\n",
       " 'adieu',\n",
       " 'adjectif',\n",
       " 'adjustment',\n",
       " 'administratif',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'admirable',\n",
       " 'adolescent',\n",
       " 'adopt',\n",
       " 'adoptif',\n",
       " 'adoption',\n",
       " 'adorability',\n",
       " 'adorateur',\n",
       " 'adorn',\n",
       " 'adresse',\n",
       " 'adult',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advani',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adversaire',\n",
       " 'adversarial',\n",
       " 'adversary',\n",
       " 'advertisement',\n",
       " 'advertiser',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'adviser',\n",
       " 'advisor',\n",
       " 'advisory',\n",
       " 'advocate',\n",
       " 'aerien',\n",
       " 'aeroport',\n",
       " 'affair',\n",
       " 'affaire',\n",
       " 'affaires',\n",
       " 'affect',\n",
       " 'affectif',\n",
       " 'affiche',\n",
       " 'affide',\n",
       " 'affiliation',\n",
       " 'affirm',\n",
       " 'affirmative',\n",
       " 'affirme-t-il',\n",
       " 'affligeant',\n",
       " 'afford',\n",
       " 'affrontement',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afp',\n",
       " 'africa',\n",
       " 'africain',\n",
       " 'african',\n",
       " 'afrikaner',\n",
       " 'afrikaners',\n",
       " 'afrique',\n",
       " 'afro-americains',\n",
       " 'afro-american',\n",
       " 'aftermath',\n",
       " 'again',\n",
       " 'age',\n",
       " 'agence',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggiornamento',\n",
       " 'agglomeration',\n",
       " 'aggravation',\n",
       " 'aggressive',\n",
       " 'aggressor',\n",
       " 'agree',\n",
       " 'agreement',\n",
       " 'agressif',\n",
       " 'agricole',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'aharonot',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aids',\n",
       " 'aiea',\n",
       " 'aigu',\n",
       " 'ailleurs',\n",
       " 'aim',\n",
       " 'ainsi',\n",
       " 'air',\n",
       " 'air-conditioned',\n",
       " 'aire',\n",
       " 'airforce',\n",
       " 'airline',\n",
       " 'airlines',\n",
       " 'airport',\n",
       " 'airspace',\n",
       " 'airwaves',\n",
       " 'aise',\n",
       " 'ajournement',\n",
       " 'ajouta-t-il',\n",
       " 'ajustement',\n",
       " 'al',\n",
       " 'al-assad',\n",
       " 'al-baradei',\n",
       " 'al-hanoun',\n",
       " 'al-muqataa',\n",
       " 'al-qaida',\n",
       " 'al-sadat',\n",
       " 'al-sadate',\n",
       " 'al-sharaa',\n",
       " 'al-sharif',\n",
       " 'alain',\n",
       " 'alarm',\n",
       " 'alarming',\n",
       " 'alcatel',\n",
       " 'aleatoire',\n",
       " 'aleksander',\n",
       " 'alexandre',\n",
       " 'algerian',\n",
       " 'algerien',\n",
       " 'ali',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienation',\n",
       " 'alinea',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'all-out',\n",
       " 'all-time',\n",
       " 'all-white',\n",
       " 'allechant',\n",
       " 'allee',\n",
       " 'alleged',\n",
       " 'allegement',\n",
       " 'allegre',\n",
       " 'allemagne',\n",
       " 'allemand',\n",
       " 'allemands',\n",
       " 'alley',\n",
       " 'alliance',\n",
       " 'allie',\n",
       " 'allocate',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allumage',\n",
       " 'allusion',\n",
       " 'ally',\n",
       " 'alors',\n",
       " 'alt-rock',\n",
       " 'alternatif',\n",
       " 'alternative',\n",
       " 'amazon',\n",
       " 'amazonie',\n",
       " 'ambassade',\n",
       " 'ambassadeur',\n",
       " 'ambassador',\n",
       " 'ambiance',\n",
       " 'ambiguite',\n",
       " 'ambition',\n",
       " 'ame',\n",
       " 'amelioration',\n",
       " 'amenable',\n",
       " 'amendement',\n",
       " 'amendment',\n",
       " 'amenity',\n",
       " 'amerada',\n",
       " 'america',\n",
       " 'americain',\n",
       " 'americaine',\n",
       " 'americains',\n",
       " 'american',\n",
       " 'americano-sovietique',\n",
       " 'americans',\n",
       " 'amerique',\n",
       " 'ami',\n",
       " 'amman',\n",
       " 'amnon',\n",
       " 'amount',\n",
       " 'amour',\n",
       " 'amp',\n",
       " 'ampleur',\n",
       " 'ampoule',\n",
       " 'amram',\n",
       " 'an',\n",
       " 'analogue',\n",
       " 'ancetre',\n",
       " 'anchor',\n",
       " 'ancien',\n",
       " 'angeles',\n",
       " 'anger',\n",
       " 'anglais',\n",
       " 'angoissantes',\n",
       " 'angoisse',\n",
       " 'angola',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anima',\n",
       " 'animateur',\n",
       " 'ankle',\n",
       " 'annan',\n",
       " 'annee',\n",
       " 'annexe',\n",
       " 'annihilate',\n",
       " 'annonce-t-il',\n",
       " 'annonceur',\n",
       " 'announce',\n",
       " 'annual',\n",
       " 'annuel',\n",
       " 'annulation',\n",
       " 'anonyme',\n",
       " 'anouar',\n",
       " 'ansar',\n",
       " 'answer',\n",
       " 'antagonise',\n",
       " 'antan',\n",
       " 'anterieur',\n",
       " 'anthrax',\n",
       " 'anthropologist',\n",
       " 'anthropologue',\n",
       " 'anti-anthrax',\n",
       " 'anti-ballistic',\n",
       " 'anti-banlieue',\n",
       " 'anti-communist',\n",
       " 'anti-indian',\n",
       " 'anti-indien',\n",
       " 'anti-personnel',\n",
       " 'anti-racist',\n",
       " 'anti-semitic',\n",
       " 'anti-sprawl',\n",
       " 'anti-suburban',\n",
       " 'anti-tank',\n",
       " 'anti-war',\n",
       " 'antibalistique',\n",
       " 'antibiotic',\n",
       " 'antibiotique',\n",
       " 'antichar',\n",
       " 'anticommunisme',\n",
       " 'anticommuniste',\n",
       " 'antidote',\n",
       " 'antilles',\n",
       " 'antimissile',\n",
       " 'antinomique',\n",
       " 'antipalestinienne',\n",
       " 'antipersonnel',\n",
       " 'antique',\n",
       " 'antisemite',\n",
       " 'anwar',\n",
       " 'anxious',\n",
       " 'anything',\n",
       " 'aol',\n",
       " 'aol-time',\n",
       " 'aopig',\n",
       " 'aout',\n",
       " 'apartment',\n",
       " 'aphc',\n",
       " 'apology',\n",
       " 'apotheosis',\n",
       " 'appall',\n",
       " 'appalling',\n",
       " 'appareil',\n",
       " 'apparent',\n",
       " 'appartenance',\n",
       " 'appauvris',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appease',\n",
       " 'appel',\n",
       " 'appelant',\n",
       " 'appellation',\n",
       " 'appetite',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appoint',\n",
       " 'appointment',\n",
       " 'apport',\n",
       " 'approach',\n",
       " 'approche',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approvisionnement',\n",
       " 'appui',\n",
       " 'apre',\n",
       " 'apres-',\n",
       " 'apres-11',\n",
       " 'april',\n",
       " 'arab',\n",
       " 'arab-jewish',\n",
       " 'arabe',\n",
       " 'arabes',\n",
       " 'arabia',\n",
       " 'arabic',\n",
       " 'arabie',\n",
       " 'arabique',\n",
       " 'arabo-juif',\n",
       " 'arabo-persique',\n",
       " 'arabs',\n",
       " 'arafat',\n",
       " 'arap',\n",
       " 'arbitrage',\n",
       " 'arbre',\n",
       " 'arbuste',\n",
       " 'archaisme',\n",
       " 'archeological',\n",
       " 'archipel',\n",
       " 'architect',\n",
       " 'architecte',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'argent',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'ariel',\n",
       " 'arise',\n",
       " 'arlie',\n",
       " 'arm',\n",
       " 'arme',\n",
       " 'armed',\n",
       " 'armee',\n",
       " 'armement',\n",
       " 'armes',\n",
       " 'armoured',\n",
       " 'arms',\n",
       " 'armure',\n",
       " 'army',\n",
       " 'arnold',\n",
       " 'arnott',\n",
       " 'aron',\n",
       " 'arouse',\n",
       " 'arrangeant',\n",
       " 'arrangement',\n",
       " 'arrears',\n",
       " 'arrest',\n",
       " 'arrestation',\n",
       " 'arret',\n",
       " 'arrete',\n",
       " 'arriere',\n",
       " 'arrive',\n",
       " 'arrive|arrivee',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'arterial',\n",
       " 'article',\n",
       " 'artillerie',\n",
       " 'artillery',\n",
       " 'artisanal',\n",
       " 'artist',\n",
       " 'artiste',\n",
       " 'artistes-peintres',\n",
       " 'artwork',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asiatique',\n",
       " 'asie',\n",
       " 'ask',\n",
       " 'aspect',\n",
       " 'aspiration',\n",
       " 'aspirin',\n",
       " 'aspirine',\n",
       " 'aspiring',\n",
       " 'assad',\n",
       " 'assassinat',\n",
       " 'assassinate',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assemblee',\n",
       " 'assembly',\n",
       " 'asservissement',\n",
       " 'assign',\n",
       " 'assignment',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'association',\n",
       " 'associations',\n",
       " 'associe',\n",
       " 'assume',\n",
       " 'assurance-maladie',\n",
       " 'assure',\n",
       " 'astound',\n",
       " 'astronomique',\n",
       " 'astuce',\n",
       " 'asymetrique',\n",
       " 'asymmetric',\n",
       " 'atal',\n",
       " 'atelier',\n",
       " 'atlantic',\n",
       " 'atlantique',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atomic',\n",
       " 'atomique',\n",
       " 'attach',\n",
       " 'attachement',\n",
       " 'attack',\n",
       " 'attaque',\n",
       " 'atteinte',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attentat',\n",
       " 'attentat-suicide',\n",
       " 'attentats-suicides',\n",
       " 'attente',\n",
       " 'attention',\n",
       " 'attirail',\n",
       " 'attirant',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attractive',\n",
       " 'attractiveness',\n",
       " 'attribution',\n",
       " 'attrition',\n",
       " 'au',\n",
       " 'auction',\n",
       " 'aucun',\n",
       " 'aucune',\n",
       " 'audacieuse',\n",
       " 'audacieux',\n",
       " 'audience',\n",
       " 'auditeur',\n",
       " 'augmentation',\n",
       " 'august',\n",
       " 'auspice',\n",
       " 'australia',\n",
       " 'australie',\n",
       " 'austrian',\n",
       " 'autant',\n",
       " 'autel',\n",
       " 'auteur',\n",
       " 'authentic',\n",
       " 'authenticite',\n",
       " 'authenticity',\n",
       " 'authentique',\n",
       " 'authorisation',\n",
       " 'authorise',\n",
       " 'authority',\n",
       " 'autobiography',\n",
       " 'autocentre',\n",
       " 'autodetermination',\n",
       " 'automated',\n",
       " 'automobile',\n",
       " 'automobile-based',\n",
       " 'autonome',\n",
       " 'autonomie',\n",
       " 'autonomisation',\n",
       " 'autonomous',\n",
       " 'autonomy',\n",
       " 'autorisation',\n",
       " 'autorite',\n",
       " 'autre',\n",
       " 'autres',\n",
       " 'autrichien',\n",
       " 'aux',\n",
       " 'avail',\n",
       " 'available',\n",
       " 'avait-elle',\n",
       " 'avait-il',\n",
       " 'avance',\n",
       " 'avancee',\n",
       " 'avantage',\n",
       " 'avantageux',\n",
       " 'avare',\n",
       " 'avec',\n",
       " 'avenement',\n",
       " 'avenir',\n",
       " 'aventure',\n",
       " 'aventurisme',\n",
       " 'aventuriste',\n",
       " 'average',\n",
       " 'avertissement',\n",
       " 'aveugle',\n",
       " 'avide',\n",
       " 'avidite',\n",
       " 'aviv',\n",
       " 'avnery',\n",
       " 'avocat',\n",
       " 'avoid',\n",
       " 'avoir',\n",
       " 'avril',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'axe',\n",
       " 'axis',\n",
       " 'ayalon',\n",
       " 'ayant',\n",
       " 'azikiwe',\n",
       " 'aziz',\n",
       " 'b',\n",
       " \"b'tselem\",\n",
       " 'baby-foot',\n",
       " 'bachar',\n",
       " 'bacille',\n",
       " 'back',\n",
       " 'back-to-africa',\n",
       " 'backing',\n",
       " 'backlash',\n",
       " 'bad',\n",
       " 'badar',\n",
       " 'badge',\n",
       " 'bagdad',\n",
       " 'baghdad',\n",
       " 'bagne',\n",
       " 'bail',\n",
       " 'bailleur',\n",
       " 'bain',\n",
       " 'baisse',\n",
       " 'baizo',\n",
       " 'balai',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balistique',\n",
       " 'balkanisation',\n",
       " 'ball',\n",
       " 'ballade',\n",
       " 'balle',\n",
       " 'ballistic',\n",
       " 'ballon',\n",
       " 'balneaire',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'bananiere',\n",
       " 'bancaire',\n",
       " 'band',\n",
       " 'bande',\n",
       " 'bandwagon',\n",
       " 'bangladesh',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'banking',\n",
       " 'banlieue',\n",
       " 'banlieusard',\n",
       " 'banner',\n",
       " 'banniere',\n",
       " 'banque',\n",
       " 'banquier',\n",
       " 'baptist',\n",
       " 'bar',\n",
       " 'barak',\n",
       " 'baramula',\n",
       " 'baramulla',\n",
       " 'barbara',\n",
       " 'barbarie',\n",
       " 'barbarism',\n",
       " 'barbed',\n",
       " 'barbele',\n",
       " 'bargain',\n",
       " 'bargaining',\n",
       " 'bargouthi',\n",
       " 'baril',\n",
       " 'baronial',\n",
       " 'barrage',\n",
       " 'barrel',\n",
       " 'barrier',\n",
       " 'barrister',\n",
       " 'barry',\n",
       " 'bas',\n",
       " 'base',\n",
       " 'bashar',\n",
       " 'basic',\n",
       " 'basie',\n",
       " 'basis',\n",
       " 'basket-ball',\n",
       " 'basketball',\n",
       " 'bastion',\n",
       " 'bataille',\n",
       " 'bataillon',\n",
       " 'bateau',\n",
       " 'bateaux-hotels',\n",
       " 'batiment',\n",
       " 'battalion',\n",
       " 'battle',\n",
       " 'bayer',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beau',\n",
       " 'beau-frere',\n",
       " 'beautiful',\n",
       " 'beck',\n",
       " 'become',\n",
       " 'beer',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behaviour',\n",
       " 'beijing',\n",
       " 'beilin',\n",
       " 'being',\n",
       " 'beirut',\n",
       " 'belantes',\n",
       " 'belarus',\n",
       " 'belarusians',\n",
       " 'belgique',\n",
       " 'belgium',\n",
       " 'belie',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'belligerent',\n",
       " 'belong',\n",
       " 'ben',\n",
       " 'beneficiaire',\n",
       " 'beneficial',\n",
       " 'beneficiary',\n",
       " 'beneficier',\n",
       " 'benefique',\n",
       " 'benefit',\n",
       " 'benevole',\n",
       " 'benjamin',\n",
       " 'bent',\n",
       " 'benyamin',\n",
       " 'beres',\n",
       " 'berlin',\n",
       " 'berlin-moscou',\n",
       " 'berlusconi',\n",
       " 'bernard-henri',\n",
       " 'berslusconi',\n",
       " 'besieged',\n",
       " 'besoin',\n",
       " 'bet',\n",
       " 'bethleem',\n",
       " 'bethlehem',\n",
       " 'beton',\n",
       " 'betselem',\n",
       " 'beyrouth',\n",
       " 'bhat',\n",
       " 'bhutto',\n",
       " 'bialystok',\n",
       " 'bidder',\n",
       " 'bielorusses',\n",
       " 'bielorussie',\n",
       " 'bien',\n",
       " 'bien-etre',\n",
       " 'bienfait',\n",
       " 'bienvenu|bienvenue',\n",
       " 'biere',\n",
       " 'big',\n",
       " 'bihari',\n",
       " 'bilan',\n",
       " 'bilateral',\n",
       " 'bill',\n",
       " 'billet',\n",
       " 'billion',\n",
       " 'bin',\n",
       " 'bind',\n",
       " 'binding',\n",
       " 'binge',\n",
       " 'binyamin',\n",
       " 'biological',\n",
       " 'biologique',\n",
       " 'bipolar',\n",
       " 'bipolarite',\n",
       " 'bis',\n",
       " 'bismarck',\n",
       " 'bit',\n",
       " 'bitter',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'blackmail',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blanc',\n",
       " 'blanche',\n",
       " 'blanchis-',\n",
       " 'bland',\n",
       " 'bleak',\n",
       " 'blesse',\n",
       " 'blinde',\n",
       " 'blithe',\n",
       " 'blix',\n",
       " 'bloc',\n",
       " 'block',\n",
       " 'blockade',\n",
       " 'blocus',\n",
       " 'bloodshed',\n",
       " 'bloody',\n",
       " 'bloque',\n",
       " 'blossom',\n",
       " 'blow',\n",
       " 'blur',\n",
       " 'bmatt',\n",
       " 'board',\n",
       " 'boast',\n",
       " 'boat',\n",
       " 'body',\n",
       " 'boheme',\n",
       " 'bohemian',\n",
       " 'boigny',\n",
       " 'bois',\n",
       " 'boisson',\n",
       " 'boite',\n",
       " 'bold',\n",
       " 'bolster',\n",
       " 'bomb',\n",
       " 'bombardement',\n",
       " 'bombing',\n",
       " 'bon',\n",
       " 'bone',\n",
       " 'book',\n",
       " 'bookstore',\n",
       " 'boom',\n",
       " 'boost',\n",
       " 'bord',\n",
       " 'border',\n",
       " 'bordure',\n",
       " 'borne',\n",
       " 'borrow',\n",
       " 'bosnia',\n",
       " 'boss',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bouc',\n",
       " 'bouclier',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'boundary',\n",
       " 'bouquet',\n",
       " 'bourrier',\n",
       " 'boursier',\n",
       " 'bout',\n",
       " 'bouteille',\n",
       " 'boutique',\n",
       " 'bouygues',\n",
       " 'bowling',\n",
       " 'box',\n",
       " 'box-like',\n",
       " 'boy',\n",
       " 'boycott',\n",
       " 'brace',\n",
       " 'brand',\n",
       " 'bras',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'brazilian',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadstuff',\n",
       " 'break',\n",
       " 'break-up',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breche',\n",
       " 'breed',\n",
       " 'breizh',\n",
       " 'bresil',\n",
       " 'bresilien',\n",
       " 'breton',\n",
       " 'brevet',\n",
       " 'bridge',\n",
       " 'brigade',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'britanniques',\n",
       " 'british',\n",
       " 'broadcast',\n",
       " 'brochure',\n",
       " 'brokerage',\n",
       " 'broom',\n",
       " 'bros',\n",
       " 'brother',\n",
       " 'brother-in-law',\n",
       " 'brouillard',\n",
       " 'brown',\n",
       " 'bruising',\n",
       " 'brundtland',\n",
       " 'brusque',\n",
       " 'brussels',\n",
       " 'brut',\n",
       " 'brutal',\n",
       " 'brutalite',\n",
       " 'brutality',\n",
       " 'bruxelles',\n",
       " 'bruyant',\n",
       " 'bryant',\n",
       " 'bubble',\n",
       " 'budget',\n",
       " 'budgetaire',\n",
       " 'budgetary',\n",
       " 'budweiser',\n",
       " 'bugs',\n",
       " 'build',\n",
       " 'build-a-bear',\n",
       " 'building',\n",
       " 'bulk',\n",
       " 'bulldozer',\n",
       " 'bulle',\n",
       " 'bullet',\n",
       " 'bullet-proof',\n",
       " 'bully',\n",
       " 'bunker',\n",
       " 'bunny',\n",
       " 'buoyant',\n",
       " 'burbs',\n",
       " 'bureau',\n",
       " 'bureaucracy',\n",
       " 'bureaucrat',\n",
       " 'bureaucratic',\n",
       " 'bureaucratie',\n",
       " 'burghardt',\n",
       " 'burghart',\n",
       " 'burn',\n",
       " 'burner',\n",
       " 'burst',\n",
       " 'burundi',\n",
       " 'bury',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'businessman',\n",
       " 'bustani',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'by-product',\n",
       " 'byway',\n",
       " \"c'\",\n",
       " 'cabinet',\n",
       " 'cachemire',\n",
       " 'cachemiri',\n",
       " 'cachemiris',\n",
       " 'cadre',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'calcul',\n",
       " 'calculate',\n",
       " 'calibre',\n",
       " 'california',\n",
       " 'californie',\n",
       " 'californien',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'calme',\n",
       " 'camarade',\n",
       " 'camera',\n",
       " 'camion',\n",
       " 'camp',\n",
       " 'campagne',\n",
       " 'campaign',\n",
       " 'campaigning',\n",
       " 'campus',\n",
       " 'canal',\n",
       " 'canalsatellite',\n",
       " 'cancellation',\n",
       " 'candidat',\n",
       " 'candidate',\n",
       " 'canton',\n",
       " 'capable',\n",
       " 'capacite',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " ...]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tousLesTermes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = np.zeros([len(indexDocuments),len(indexInverse)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALLOW_THREADS', 'AxisError', 'BUFSIZE', 'CLIP', 'ComplexWarning', 'DataSource', 'ERR_CALL', 'ERR_DEFAULT', 'ERR_IGNORE', 'ERR_LOG', 'ERR_PRINT', 'ERR_RAISE', 'ERR_WARN', 'FLOATING_POINT_SUPPORT', 'FPE_DIVIDEBYZERO', 'FPE_INVALID', 'FPE_OVERFLOW', 'FPE_UNDERFLOW', 'False_', 'Inf', 'Infinity', 'MAXDIMS', 'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'MachAr', 'ModuleDeprecationWarning', 'NAN', 'NINF', 'NZERO', 'NaN', 'PINF', 'PZERO', 'RAISE', 'RankWarning', 'SHIFT_DIVIDEBYZERO', 'SHIFT_INVALID', 'SHIFT_OVERFLOW', 'SHIFT_UNDERFLOW', 'ScalarType', 'Tester', 'TooHardError', 'True_', 'UFUNC_BUFSIZE_DEFAULT', 'UFUNC_PYVALS_NAME', 'VisibleDeprecationWarning', 'WRAP', '_NoValue', '_UFUNC_API', '__NUMPY_SETUP__', '__all__', '__builtins__', '__cached__', '__config__', '__doc__', '__file__', '__git_revision__', '__loader__', '__mkl_version__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_add_newdoc_ufunc', '_arg', '_distributor_init', '_globals', '_mat', '_mklinit', '_pytesttester', 'abs', 'absolute', 'absolute_import', 'add', 'add_docstring', 'add_newdoc', 'add_newdoc_ufunc', 'alen', 'all', 'allclose', 'alltrue', 'amax', 'amin', 'angle', 'any', 'append', 'apply_along_axis', 'apply_over_axes', 'arange', 'arccos', 'arccosh', 'arcsin', 'arcsinh', 'arctan', 'arctan2', 'arctanh', 'argmax', 'argmin', 'argpartition', 'argsort', 'argwhere', 'around', 'array', 'array2string', 'array_equal', 'array_equiv', 'array_repr', 'array_split', 'array_str', 'asanyarray', 'asarray', 'asarray_chkfinite', 'ascontiguousarray', 'asfarray', 'asfortranarray', 'asmatrix', 'asscalar', 'atleast_1d', 'atleast_2d', 'atleast_3d', 'average', 'bartlett', 'base_repr', 'binary_repr', 'bincount', 'bitwise_and', 'bitwise_not', 'bitwise_or', 'bitwise_xor', 'blackman', 'block', 'bmat', 'bool', 'bool8', 'bool_', 'broadcast', 'broadcast_arrays', 'broadcast_to', 'busday_count', 'busday_offset', 'busdaycalendar', 'byte', 'byte_bounds', 'bytes0', 'bytes_', 'c_', 'can_cast', 'cast', 'cbrt', 'cdouble', 'ceil', 'cfloat', 'char', 'character', 'chararray', 'choose', 'clip', 'clongdouble', 'clongfloat', 'column_stack', 'common_type', 'compare_chararrays', 'compat', 'complex', 'complex128', 'complex256', 'complex64', 'complex_', 'complexfloating', 'compress', 'concatenate', 'conj', 'conjugate', 'convolve', 'copy', 'copysign', 'copyto', 'core', 'corrcoef', 'correlate', 'cos', 'cosh', 'count_nonzero', 'cov', 'cross', 'csingle', 'ctypeslib', 'cumprod', 'cumproduct', 'cumsum', 'datetime64', 'datetime_as_string', 'datetime_data', 'deg2rad', 'degrees', 'delete', 'deprecate', 'deprecate_with_doc', 'diag', 'diag_indices', 'diag_indices_from', 'diagflat', 'diagonal', 'diff', 'digitize', 'disp', 'divide', 'division', 'divmod', 'dot', 'double', 'dsplit', 'dstack', 'dtype', 'e', 'ediff1d', 'einsum', 'einsum_path', 'emath', 'empty', 'empty_like', 'equal', 'errstate', 'euler_gamma', 'exp', 'exp2', 'expand_dims', 'expm1', 'extract', 'eye', 'fabs', 'fastCopyAndTranspose', 'fft', 'fill_diagonal', 'find_common_type', 'finfo', 'fix', 'flatiter', 'flatnonzero', 'flexible', 'flip', 'fliplr', 'flipud', 'float', 'float128', 'float16', 'float32', 'float64', 'float_', 'float_power', 'floating', 'floor', 'floor_divide', 'fmax', 'fmin', 'fmod', 'format_float_positional', 'format_float_scientific', 'format_parser', 'frexp', 'frombuffer', 'fromfile', 'fromfunction', 'fromiter', 'frompyfunc', 'fromregex', 'fromstring', 'full', 'full_like', 'fv', 'gcd', 'generic', 'genfromtxt', 'geomspace', 'get_array_wrap', 'get_include', 'get_printoptions', 'getbufsize', 'geterr', 'geterrcall', 'geterrobj', 'gradient', 'greater', 'greater_equal', 'half', 'hamming', 'hanning', 'heaviside', 'histogram', 'histogram2d', 'histogram_bin_edges', 'histogramdd', 'hsplit', 'hstack', 'hypot', 'i0', 'identity', 'iinfo', 'imag', 'in1d', 'index_exp', 'indices', 'inexact', 'inf', 'info', 'infty', 'inner', 'insert', 'int', 'int0', 'int16', 'int32', 'int64', 'int8', 'int_', 'int_asbuffer', 'intc', 'integer', 'interp', 'intersect1d', 'intp', 'invert', 'ipmt', 'irr', 'is_busday', 'isclose', 'iscomplex', 'iscomplexobj', 'isfinite', 'isfortran', 'isin', 'isinf', 'isnan', 'isnat', 'isneginf', 'isposinf', 'isreal', 'isrealobj', 'isscalar', 'issctype', 'issubclass_', 'issubdtype', 'issubsctype', 'iterable', 'ix_', 'kaiser', 'kron', 'lcm', 'ldexp', 'left_shift', 'less', 'less_equal', 'lexsort', 'lib', 'linalg', 'linspace', 'little_endian', 'load', 'loads', 'loadtxt', 'log', 'log10', 'log1p', 'log2', 'logaddexp', 'logaddexp2', 'logical_and', 'logical_not', 'logical_or', 'logical_xor', 'logspace', 'long', 'longcomplex', 'longdouble', 'longfloat', 'longlong', 'lookfor', 'ma', 'mafromtxt', 'mask_indices', 'mat', 'math', 'matmul', 'matrix', 'matrixlib', 'max', 'maximum', 'maximum_sctype', 'may_share_memory', 'mean', 'median', 'memmap', 'meshgrid', 'mgrid', 'min', 'min_scalar_type', 'minimum', 'mintypecode', 'mirr', 'mod', 'modf', 'moveaxis', 'msort', 'multiply', 'nan', 'nan_to_num', 'nanargmax', 'nanargmin', 'nancumprod', 'nancumsum', 'nanmax', 'nanmean', 'nanmedian', 'nanmin', 'nanpercentile', 'nanprod', 'nanquantile', 'nanstd', 'nansum', 'nanvar', 'nbytes', 'ndarray', 'ndenumerate', 'ndfromtxt', 'ndim', 'ndindex', 'nditer', 'negative', 'nested_iters', 'newaxis', 'nextafter', 'nonzero', 'not_equal', 'nper', 'npv', 'numarray', 'number', 'obj2sctype', 'object', 'object0', 'object_', 'ogrid', 'oldnumeric', 'ones', 'ones_like', 'outer', 'packbits', 'pad', 'partition', 'percentile', 'pi', 'piecewise', 'place', 'pmt', 'poly', 'poly1d', 'polyadd', 'polyder', 'polydiv', 'polyfit', 'polyint', 'polymul', 'polynomial', 'polysub', 'polyval', 'positive', 'power', 'ppmt', 'print_function', 'printoptions', 'prod', 'product', 'promote_types', 'ptp', 'put', 'put_along_axis', 'putmask', 'pv', 'quantile', 'r_', 'rad2deg', 'radians', 'random', 'rank', 'rate', 'ravel', 'ravel_multi_index', 'real', 'real_if_close', 'rec', 'recarray', 'recfromcsv', 'recfromtxt', 'reciprocal', 'record', 'remainder', 'repeat', 'require', 'reshape', 'resize', 'result_type', 'right_shift', 'rint', 'roll', 'rollaxis', 'roots', 'rot90', 'round', 'round_', 'row_stack', 's_', 'safe_eval', 'save', 'savetxt', 'savez', 'savez_compressed', 'sctype2char', 'sctypeDict', 'sctypeNA', 'sctypes', 'searchsorted', 'select', 'set_numeric_ops', 'set_printoptions', 'set_string_function', 'setbufsize', 'setdiff1d', 'seterr', 'seterrcall', 'seterrobj', 'setxor1d', 'shape', 'shares_memory', 'short', 'show_config', 'sign', 'signbit', 'signedinteger', 'sin', 'sinc', 'single', 'singlecomplex', 'sinh', 'size', 'sometrue', 'sort', 'sort_complex', 'source', 'spacing', 'split', 'sqrt', 'square', 'squeeze', 'stack', 'std', 'str', 'str0', 'str_', 'string_', 'subtract', 'sum', 'swapaxes', 'sys', 'take', 'take_along_axis', 'tan', 'tanh', 'tensordot', 'test', 'testing', 'tile', 'timedelta64', 'trace', 'tracemalloc_domain', 'transpose', 'trapz', 'tri', 'tril', 'tril_indices', 'tril_indices_from', 'trim_zeros', 'triu', 'triu_indices', 'triu_indices_from', 'true_divide', 'trunc', 'typeDict', 'typeNA', 'typecodes', 'typename', 'ubyte', 'ufunc', 'uint', 'uint0', 'uint16', 'uint32', 'uint64', 'uint8', 'uintc', 'uintp', 'ulonglong', 'unicode', 'unicode_', 'union1d', 'unique', 'unpackbits', 'unravel_index', 'unsignedinteger', 'unwrap', 'ushort', 'vander', 'var', 'vdot', 'vectorize', 'version', 'void', 'void0', 'vsplit', 'vstack', 'warnings', 'where', 'who', 'zeros', 'zeros_like']\n"
     ]
    }
   ],
   "source": [
    "print(dir(np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
